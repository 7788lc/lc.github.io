[{"title":"偏态与峰态的度量","url":"/2021/09/22/偏态与峰态/","content":"**偏态与峰态的度量**\n\n偏态和峰态是对数据分布形状的测度，通过它们可以知道数据分布形状是否对称,偏斜程度以及分布的扁平程度等。\n\n**偏态**\n\n偏态相对与正态分布而言，偏态可以体现异常值的分布方向。\n\n很多统计模型假设前提是数据符合正态分布，数据如果严重偏斜，会影响模型输出结果，所以在输入模型前要观察数据的偏度，以免影响模型输出结果\n\n测度偏态的统计量是偏态系数\n\n偏度系数大于0，说明数据右偏或正偏\n\n偏度系数小于0，说明数据左偏或负偏\n\n偏度系数等于0，说明数据分布是对称的\n\n未分组数据 $$SK= \\frac{n\\sum{ (x_i - \\overline{x}) ^3}}{(n-1)(n-2)s^3} $$\n\n$s^3$是样本标准差的3次方\n\n分组数据  $$SK= \\frac{\\sum _{i=1}^k(M_i-\\overline{x}) ^3 f_i }{ns^3}$$\n\n其中$M_i$是分组数据的组中值\n\n\n处理偏态数据常用方法：\n\n1.取对数\n\n2.指数变换法\n\n3.幂变换\n\n4.平方根变换\n\n5.box-cox变换\n\n\n```python\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats import mode\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import skew\nsns.set(style='white',context='notebook',palette='muted')\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv('train.csv')\ncopy = train.sample(200)\ncopy\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>626</th>\n      <td>627</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Kirkland, Rev. Charles Leonard</td>\n      <td>male</td>\n      <td>57.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>219533</td>\n      <td>12.3500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>482</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>239854</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>850</th>\n      <td>851</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Andersson, Master. Sigvard Harald Elias</td>\n      <td>male</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>347082</td>\n      <td>31.2750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>136</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Richard, Mr. Emile</td>\n      <td>male</td>\n      <td>23.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SC/PARIS 2133</td>\n      <td>15.0458</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>230</th>\n      <td>231</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Harris, Mrs. Henry Birkhardt (Irene Wallach)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>36973</td>\n      <td>83.4750</td>\n      <td>C83</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>548</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Padro y Manent, Mr. Julian</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SC/PARIS 2146</td>\n      <td>13.8625</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>524</th>\n      <td>525</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Kassem, Mr. Fared</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2700</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>469</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Scanlan, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36209</td>\n      <td>7.7250</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>859</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Baclini, Mrs. Solomon (Latifa Qurban)</td>\n      <td>female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2666</td>\n      <td>19.2583</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>508</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Bradley, Mr. George (\"George Arthur Brayton\")</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111427</td>\n      <td>26.5500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 12 columns</p>\n</div>\n\n\n\n\n```python\n#以泰坦尼克数据为例，查看票价的偏度\nskew(copy['Fare'])\n#抽取的样本中票价偏度为右偏，数据偏度高度正偏\n\n\n```\n\n\n\n\n    3.2250338215549292\n\n\n\n\n```python\n#使用直方图观察\n#抽取的样本中票价偏度为右偏，数据偏度高度正偏，数据集中在左侧\np = sns.distplot(copy['Fare'],label='skewness%.2f')\np.legend(loc='best')\n```\n\n\n\n\n    <matplotlib.legend.Legend at 0x1624baad390>\n\n\n\n\n![png](output_3_1.png)\n\n\n**峰态及其测度**\n\n峰态是与正态分布而言，它是对数据分布平峰或尖峰程度的测试\n\n正态分布峰度系数为3\n\n测度峰态的统计量是峰度系数\n\n\n\n未分组数据：\n$$K = \\frac{n(n+1)\\sum(x_i-\\overline{x})^4-3\\big[\\sum(x_i-\\overline{x})^2\\big]^2(n-1)} {(n-1)(n-2)(n-3)s^4}$$\n\n分组数据：\n$$K=\\frac{\\sum_{i=1}^k(M_i-\\overline{x})^4f_i}{ns^4} -3 $$\n\n减去3是为了使比较标准变为0，因为正态分布峰度系数为3\n\n\n\n```python\nimport scipy.stats as st\n#标准正态分布的峰度系数\ns = np.random.normal(size=1000)\n#使用pearson定义  不减去3\nst.kurtosis(s,fisher=False)\n```\n\n\n\n\n    3.0323313898498414\n\n\n\n\n```python\n\n#使用默认fisher定义  减去3\nst.kurtosis(s)\n```\n\n\n\n\n    0.34768257633927524\n\n\n","tags":["数据度量"],"categories":["统计"]},{"title":"秦九昭算法","url":"/2021/09/22/多项式求值/","content":"**多项式求值的秦九昭算法**\n\n给定n次多项式：\n\n$$ p(x) = a_0x^n + a_1x^{n-1}+...+a_{n-1}x+a_n, 其中a_0 \\neq0 $$\n\n求$$x^*处的p(x^*)的值$$\n\n如果直接计算，第n次项需要n次乘法，第n-1次项需要n-1次乘法，以此类推，n次多项式总共需要乘法的次数计算：\n\n$$1+2+3+...+n = \\frac{n(n+1)}{2} = \\frac{n^2}{2}+\\frac{n}{2}$$\n\n去掉低次项和常数，共需要$O(n^2)$次乘法，并且还需要n次加法\n\n\n改进算法：假设n=3,则\n$$p(x) = a_0x^3 + a_1x^2+a_2x^1+a_3$$\n\n第一次提取x得：$$x(a_0x^2+a_1x+a_2)+a_3$$\n\n第二次提取x得：$$x(x(a_0x+a_1)+a_2)+a_3$$\n\n由此归纳，可以求得n次项的公式为：\n\n$$(..(a_0x+a_1)x+...+a_{n-1})x+a_n$$\n\n它可表示为：$$ \\begin{cases} b_0=a_0 \\\\ b_i = b_{i-1}x^* +a_i , 其中 i = 1,2,...n\\end{cases}$$\n\n根据上面公式可用递归法求解多项式方程：\n\n```python\n#秦九韶算法\nimport sys\nsys.setrecursionlimit(10000)\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ncoef =3 #系数 为了方便 取一样的值\nn  =  2000 #项数\nx = 3\n#秦九韶算法\ndef polyval(n,a,x):\n    def bi(n):\n        if n==1:\n            return a*x+a\n        return bi(n-1)*x+a\n    return bi(n)\n\nbegin = time.clock()\nprint(\"计算结果：\",polyval(n,coef,x))\n\nend=time.clock()\nprint('优化算法运行时间为：{}秒'.format(end-begin))\n```\n\n    计算结果： 7865420632751932243469885786240972567380781193458348330153496053148088198022739701811689114391064999840240278132653744649471157961439788913814863909421373168428105710404897307216883328152442355836936142066769908267349005965252252915162711185165658574311724678441620806407158479616213577350933897990624356546701463481828908829431510325888983286689102858877118881081133409974499968098859657681639066408398985689710805698912647659500904210928788080053653728786390490507146819456621861814579899910393835810330421705700620967412424006596220986104598626323625831179849853089977825803525828708495714166390375521594049782922331883934183207290666460582194178320137415257581058911256076769416608658899872683384121383744716181173849253209198839349279285102205333200209363472860536817119457705863700254843720739314075664445115834713541606907464203547794689492567100212211686900918854120735898108752773954939305366002551711396827696254210469506024962532185743496980003\n    优化算法运行时间为：0.0023105000000214204秒\n    \n\n\n```python\n#暴力法\ndef bru(n,a,x):\n    def p(n): \n        if n==0:\n            return a\n        return pow(x,n)*a + p(n-1)\n    return p(n)   \n\nbegin = time.clock()\nprint(bru(n,coef,x))\nend=time.clock()\nprint('暴力算法运行时间为：{}秒'.format(end-begin))\n```\n\n    7865420632751932243469885786240972567380781193458348330153496053148088198022739701811689114391064999840240278132653744649471157961439788913814863909421373168428105710404897307216883328152442355836936142066769908267349005965252252915162711185165658574311724678441620806407158479616213577350933897990624356546701463481828908829431510325888983286689102858877118881081133409974499968098859657681639066408398985689710805698912647659500904210928788080053653728786390490507146819456621861814579899910393835810330421705700620967412424006596220986104598626323625831179849853089977825803525828708495714166390375521594049782922331883934183207290666460582194178320137415257581058911256076769416608658899872683384121383744716181173849253209198839349279285102205333200209363472860536817119457705863700254843720739314075664445115834713541606907464203547794689492567100212211686900918854120735898108752773954939305366002551711396827696254210469506024962532185743496980003\n    暴力算法运行时间为：0.007981000000199856秒\n    \n","tags":["多项式求值"],"categories":["数值"]},{"title":"数值型数据处理","url":"/2021/09/22/数值型数据/","content":"\n**数值型数据的整理与展示**\n\n数据分组：\n\n数据分组是将原始数据安装某种标准分成不同的组别，分组后的数据称为分组数据。\n\n数据分组方法分为单变量分组和组距分组\n\n其中单变量分组适用于离散变量，单变量分组是把每一个变量值作为一组。\n\n在连续变量或者变量值较多的情况，通常用组距分组。它是将全部变量依次划分为若干个区间\n并将一个区间的变量值作为一组\n\n\n\n\n```python\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv('train.csv')\n#以kaggle 泰坦尼克数据为例\n\n#这里把年龄分为6组，cut函数会自动分组\n#labels为自定义年龄段标签\nlabels = ['baby','children','teenager','youth','middle','old']\ngroup_l = pd.cut(data['Age'],6,labels=labels)\ngroup_l\n```\n\n\n\n\n    0      children\n    1      teenager\n    2      children\n    3      teenager\n    4      teenager\n             ...   \n    886    teenager\n    887    children\n    888         NaN\n    889    children\n    890    teenager\n    Name: Age, Length: 891, dtype: category\n    Categories (6, object): ['baby' < 'children' < 'teenager' < 'youth' < 'middle' < 'old']\n\n\n\n\n```python\n#可视化年龄段人数\nc = group_l.value_counts()\nprint(c)\n\nplt.bar(c.index,height=c)\n```\n\n    children    248\n    teenager    245\n    youth       100\n    baby         71\n    middle       43\n    old           7\n    Name: Age, dtype: int64\n    \n\n\n\n\n    <BarContainer object of 6 artists>\n\n\n\n\n![png](output_2_2.png)\n\n\n\n```python\ngroup = pd.cut(data['Age'],6)#不带标签的情况\ngroup#自动分成了6组  (0.34, 13.683] < (13.683, 26.947] 。。。\n```\n\n\n\n\n    0      (13.683, 26.947]\n    1       (26.947, 40.21]\n    2      (13.683, 26.947]\n    3       (26.947, 40.21]\n    4       (26.947, 40.21]\n                 ...       \n    886     (26.947, 40.21]\n    887    (13.683, 26.947]\n    888                 NaN\n    889    (13.683, 26.947]\n    890     (26.947, 40.21]\n    Name: Age, Length: 891, dtype: category\n    Categories (6, interval[float64]): [(0.34, 13.683] < (13.683, 26.947] < (26.947, 40.21] < (40.21, 53.473] < (53.473, 66.737] < (66.737, 80.0]]\n\n\n\n\n```python\n#还可以自定义区间分组\n#这里是0-3岁 3-10岁 10-18一组 以此类推\nbins = np.array([0,3,10,18,35,65,90])\nage_group = pd.cut(data['Age'],bins)\nage_group.value_counts()\n```\n\n\n\n\n    (18, 35]    358\n    (35, 65]    209\n    (10, 18]     75\n    (3, 10]      34\n    (0, 3]       30\n    (65, 90]      8\n    Name: Age, dtype: int64\n\n\n","tags":["数据预处理"],"categories":["统计"]},{"title":"数据集中趋势度量","url":"/2021/09/22/数据集中趋势度量/","content":"**集中趋势的度量**\n\n集中趋势是一组数据向某一中心值靠拢的程度，反应了一组数据中心点的位置所在。\n\n1.分类数据：众数\n\n众数是一组数据中出现次数最多的变量值\n\n众数主要用于测度分类数据的集中趋势\n\n众数不受极端值影响，如果没有明显的集中趋势或最高峰点，众数可能不存在\n\n可以有多个众数\n\n数据量少的情况不适合使用众数\n\n\n\n\n```python\nfrom scipy.stats import mode\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n#使用scipy 库的mode函数求众数\nlist = ['1','2','3','1','2','2']\nprint(mode(list))\nprint(mode(list)[0][0])\n```\n\n    ModeResult(mode=array(['2'], dtype='<U1'), count=array([3]))\n    2\n    \n\n顺序数据：中位数和分位数\n\n中位数是一组数据排序后处于中间位置的变量值\n\n适用于偏度较大的数据\n\n\n```python\n#求中位数  元素个数奇数的情况 n+1 / 2 位置的值就是中位数\n#median函数会自动排序\nodd = np.array([5,4,3,2,1])\nprint(np.median(odd))\n\n#n为偶数的情况 中间两个值之和除以2\neven = np.array([1,2,3,4,5,6])\n#3+4 /2\nprint(np.median(even))\n```\n\n    3.0\n    3.5\n    \n\n四分位数\n\n通过三个点将数据分为4部分 ----25%----50%----75%----\n\n常用算法有几种 但是差别不大\n\n例如：\n\n第一分位 Q1=(n+1)×0.25\n\n第二分位 Q 2 = ( n + 1 ) × 0.5\n\n第三分位 Q 3 = ( n + 1 ) × 0.75 \n\n其中第一分位与第三分位数中间包含了50%的数据\n\n\n\nnumpy percetile计算方法：\n\n位置 \nQ1=1+(n−1)×0.25\n\n位置 \nQ2=1+(n−1)×0.5\n\n\n位置 \nQ3=1+(n−1)×0.75\n\n\n\n\n```python\n#percentile函数求四分卫数  自动排序\np = np.array([8,7,6,5,4,3,2,1])\n\nprint(np.percentile(p,(25)))\nprint(np.percentile(p,(50)))\nprint(np.percentile(p,(75)))\n```\n\n    2.75\n    4.5\n    6.25\n    \n\n数值型数据：平均数\n\n平均数也称为均值，它是一组数据相加后除以数据总数得到的结果\n\n平均数不适用于分类数据和顺序数据，并且容易受到极大值，极小值影响\n\n\n\n\n```python\n#求平均数\nm = np.array([1,2,3,4])\nnp.mean(m)\n\n#极大值对平均数的影响\nm1 = np.array([1,2,3,4,10])\nnp.mean(m1)\n\n\n```\n\n\n\n\n    4.0\n\n\n\n加权平均数：\n\n一组数据中每个数据具有权重的情况下使用加权平均数计算均值\n\n权重一般计算方法是计算各数值出现的频率\n\naverage 函数计算加权方法 \n\n\n```python\n#average 函数计算加权方法\n#(1*3 + 2*3 + 3*4) / 3+3+4\nm = np.array([1,2,3])\nnp.average(m,weights=[3,3,4])\n```\n\n\n\n\n    2.1\n\n\n\n几何平均数\n\n1.n个变量值乘积的n次方\n\n$$G =\\sqrt[n]{X_1 \\times X_2 \\times \\cdot \\cdot \\cdot \\times X_n } = \\sqrt[n]{\\prod_{i=1}^n X_i}$$\n\n2.几何平均数主要用于计算平均比率，变量值本身是比率的形式，用几何平均法比较合理。\n\n\n\n\n```python\nfrom scipy.stats import gmean\nl = [1.045,1.021,1.255,1.019]\n\ngmean(l)\n\n\n```\n\n\n\n\n    1.0807866848335959\n\n\n","tags":["数据度量"],"categories":["统计"]},{"title":"数据离散程度的度量","url":"/2021/09/22/离散程度度量/","content":"**离散程度的度量**\n\n**离散程度反映各变量值远离其中心值的程度**\n\n****\n\n**分类数据：异众比率**\n\n异众比是指非众数的频数占总频数的比例\n\n$ V_r = \\frac {\\sum f_i-f_m}{\\sum f_i} =1- \\frac {f_m}{\\sum f_i}$\n\n式中，$ \\sum f_i $为变量值的总频数；$ f_m $为众数组的频数\n\n异众比率主要用于衡量众数对一组数据的代表程度。\n\n异众比率越大，说明非众数组频数占比大，众数的代表性被削弱了。\n\n异众比率越小，说明非众数组频数占比小，众数的代表性强。\n\n\n```python\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats import mode\nimport numpy as np\n\n\n#举例  假设调查50个人，购买碳酸饮料的15个人为众数组频数，其他人购买别的饮料类型\n#求异众比\nv= (50-15) / 50 \nprint('percent:{:.0%}'.format(v))\n```\n\n    percent:70%\n    \n\n**顺序数据：四分位差**\n\n四分位差是上四分位数与下四分位数之差\n\n$Q_d = Q_U-Q_L$\n\n四分位差反应了中间50%数据的离散程度，数值越小，中间数据越集中\n\n数值类型数据也可以计算四分位差\n\n四分位差不受极值影响\n\n*****\n\n\n**数值型数据：**\n\n1.极差\n\n一组数据最大值与最小值之差为极差，也称为全距。\n\n公式为：$ R = max(x_i) - min(x_i) $\n\n$ max(x_i) \\quad 和 \\quad min(x_i) $ 分别为最大值与最小值\n\n极差容易受极端值影响，而且由于只利用一组数据两端信息，不能反映中间数据的分散状况。\n\n2.平均差\n\n平均差是各变量值与其平均数离差绝对值的平均数\n\n**未分组数据平均差\n\n$$ M_d = \\frac{\\sum_{i=1}^n |x_i - \\overline{x} |}{n}$$\n\n**分组数据平均差\n\n$$ M_d = \\frac{\\sum_{i=1}^k |M_i - \\overline{x} |  f_i}{n}$$\n\n其中$M_i$代表数据分组的组中值, $f_i$代表分组中数据频数\n\n平均差越大 数据离散程度越大，反之离散程度越小。\n\n平均差以平均数为中心，反应每个数据与平均数的平均差异程度。\n\n实际很少用\n\n**方差**\n\n方差是各变量值与其平均数离差平方的平均数\n\n\n未分组数据样本方差：$$s^2 = \\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n-1}$$\n\n分组数据样本方差：$$s^2 = \\frac{\\sum_{i=1}^k(M_i - \\overline{x})^2 f_i}{n-1}$$\n\n其中$M_i$代表数据分组的组中值, $f_i$代表分组中数据频数\n\n样本方差是除以n-1个自由度\n\n总体方差直接除以n就行\n\n方差能较好的反映出数据的离散程度，是常用的离散程度测度值\n\n\n```python\n#python计算方差\na = np.array([[1,2],[3,4]])\na\n```\n\n\n\n\n    array([[1, 2],\n           [3, 4]])\n\n\n\n\n```python\nnp.var(a,axis=0) #按每一列计算方差  var函数内部是除以 默认自由度n  不是除以n-1\n```\n\n\n\n\n    array([1., 1.])\n\n\n\n\n```python\nnp.var(a,axis=1)#按每行计算方差\n```\n\n\n\n\n    array([0.25, 0.25])\n\n\n\n\n```python\nnp.var(a) #把矩阵展开计算总方差\n```\n\n\n\n\n    1.25\n\n\n\n**标准差**\n\n方差求平方根就是标准差\n\n未分组数据：$$s = \\sqrt{\\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n-1}}$$\n\n\n分组数据：$$s^2 = \\sqrt{\\frac{\\sum_{i=1}^k(M_i - \\overline{x})^2  f_i}{n-1}}$$\n\n\n\n\n```python\n#numpy求标准差\na = np.array([[1,2],[3,4]])\n\nnp.std(a,axis=0)\n```\n\n\n\n\n    array([1., 1.])\n\n\n\n\n```python\nnp.std(a,axis=1)\n```\n\n\n\n\n    array([0.5, 0.5])\n\n\n\n\n```python\nnp.std(a)\n```\n\n\n\n\n    1.118033988749895\n\n\n\n**标准分数 又叫Z分数**\n\nZ分数是变量值与其平均数的差除以标准差后的值\n\n标准Z分数为：\n\n$$z_i = \\frac{x_i - \\overline{x}}{s}$$\n\n\n标准分数给出了一组数据中各数据相对位置。例如某个数据的标准分数为-1.5，说明这个数据比平均数低1.5个标准差。反之是+1.5，高与平均数1.5个标准差。\n\n\nz分数具有均值为0，标准差为1的特性，它只是将数据进行了线性变换，没有改变数据分布，是对数据进行标准化处理\n\n机器学习中常用来标准化输入数据\n\n\n\n\n```python\n#numpy \na = np.array([25,28,31,34,37,40,43])\n\nz = (a - np.mean(a)) / np.std(a)\nz\n```\n\n\n\n\n    array([-1.5, -1. , -0.5,  0. ,  0.5,  1. ,  1.5])\n\n\n\n**离散系数**\n\n离散系数也称为变异系数，它是一组数据的标准差与其相应平均数之比\n\n$$cv = \\frac{s}{\\overline{x}}$$\n\n离散系数主要用于比较不同样本数据，或者量纲不同变量的离散程度，离散系数越大，数据离散程度越大，反之离散程度越小。\n\n","tags":["数据度量"],"categories":["统计"]},{"title":"离散随机变量","url":"/2021/09/22/离散随机变量/","content":"**离散型随机变量及其分布**\n\n随机变量定义：\n\n以抛两枚硬币的例子来说，抛一次实验的样本空间为S={(H,H),(H,T),(T,H),(T,T)},包含四个随机事件。如果我们只关心正面向上事件的次数，而不考虑是哪个硬币正面向上，就是把随机事件用数量表示。\n\n例如，抛两枚硬币的例子，S为样本空间，e为随机事件，令Y表示正面向上的次数，Y就是一个随机变量，它的取值可以是0,1,2次，Y=1时依赖的事件是(H,T)或(T,H)，Y=2时依赖事件{(H,H)},这样就可以把Y的值与事件e相对应。\n\n表达为函数形式Y = Y(e),于是随机变量Y就是定义在样本空间S上的实值单值函数。\n\n考虑随机变量Y=0,1,2时的概率：\n\nP{Y=0} = P{(T,T)} = 1/4\n\nP{Y=1} = P{(H,T),(T,H)} = 2/4 =1/2\n\nP{Y=2} = P{(H,H)} = 1/4\n\nP{Y<=1} = P{(H,T),(T,H),(T,T)} = 3/4\n\n\n\n\n```python\nimport random\n\ndef gen():\n    rand = random.randint(0,1)\n    return rand\n#硬币事件\ndef coin():\n    if gen()==1:\n        return 'h'\n    else:\n        return 't'\n\n \n#计算正反面 \ndef p(c1,c2):\n    \n    s = 4 #样本空间\n    y=[0,1,2] #随机变量\n    if c1 =='t' and c2=='t':\n        return y[0],1/s\n        \n    if (c1 =='h' and c2=='t') or (c1 =='t' and c2=='h'):\n        return y[1],2/s\n        \n    if c1 =='h' and c2=='h':\n        return y[2],1/s\n    \ndef rd():\n    coin1 = coin()\n    coin2 = coin()\n    return p(coin1,coin2)\n    \n\n#抛两个硬币出现0次，1次，2次正面的概率\nfor _ in range(5):\n    res = rd()\n    print(\"随机事件Y={}的概率为 ：{}\".format(res[0],res[1]))\n```\n\n    随机事件Y=2的概率为 ：0.25\n    随机事件Y=1的概率为 ：0.5\n    随机事件Y=1的概率为 ：0.5\n    随机事件Y=1的概率为 ：0.5\n    随机事件Y=1的概率为 ：0.5\n    \n\n**离散型随机变量的期望值和方差**\n\n**随机变量X的期望**：\n离散型随机变量X的一切取值与其对应概率的乘积之和。一般记做E(X)\n\n$$E(X) = x_1p_1+x_2p_2+...x_np_n = \\sum_{i=1}^nx_ip_i$$\n\n期望表示随机变量本身的平均水平或集中程度。\n\n**随机变量X的方差与标准差**：\n方差是随机变量与其数学期望的离差的平均水平，它可以测量随机变量变异程度或离散程度。\n\n方差可以反映随机变量取值的离散程度\n$$D(X) = E \\big[X-E(X)\\big]^2$$\n\n\n\n\n**二项分布**\n\n设试验E只有两种可能结果：成功或失败 ，A与$\\overline{A}$，假设P(A)=p,P($\\overline{A}$) = 1-p,这种只有两种结果的独立重复试验称为伯努利试验\n\n重复是指每次试验p(A)=p不变,独立是指各次试验结果互不影响。\n\n进行n次伯努利试验，每次成功的概率为p,成功k次的概率是多少？这个概率分布就是二项分布\n\n$$p(k) = \\big(_k^n\\big)p^k(1-p)^{n-k}, k = 0,1,2,.....,n$$\n\n由二项式定理\n\n$$(x+y)^n = \\sum_{k=0}^n\\big(_k^n\\big)x^ky^{n-k}$$\n\n得二项分布概率和为\n\n$$\\sum_{k=0}^n\\big(_k^n\\big)p^k(1-p)^{n-k}  = (p+1-p)^n = 1$$\n\n\n\n\n简单的抛硬币游戏\n\n假设抛十次硬币，k值为正面出现的次数 ，随着k值不断增加，观察每个k值对应的概率\n\n可见抛十次硬币，出现5次正面的概率最高，这也符合我们直觉，但是随着期望出现正面的次数越高，反而出现正面的这种概率在下降。\n\n\n```python\nfrom scipy import stats\nimport numpy as np\nfrom  matplotlib import pyplot as plt\nlist = []\nfor i in range(0,11):\n    p = stats.binom.pmf(i,10,0.5)#10次伯努利实验，正面概率为0.5，求i次正面的概率\n    list.append(p)\nprint(list)\n\nx = np.arange(0,11)\nplt.bar(x,height=list)\nplt.xlabel('K')\nplt.ylabel('probability')\nprint(\"二项分布概率和为 ： \",sum(list))\n```\n\n    [0.0009765625, 0.00976562500000001, 0.04394531249999999, 0.11718750000000014, 0.20507812500000022, 0.24609375000000025, 0.20507812500000022, 0.11718750000000014, 0.04394531249999999, 0.00976562500000001, 0.0009765625]\n    二项分布概率和为 ：  1.0000000000000009\n    \n\n\n![png](output_5_2.png)\n\n\n\n","tags":["离散随机变量"],"categories":["概率"]},{"title":"随机事件","url":"/2021/09/22/随机事件/","content":"**随机事件及其概率**\n\n基本概念：\n\n***样本空间**\n\n对于随机试验，其结果不可预测，但是假设所有可能的结果集合是已知的，那么所有可能的结果构成的集合，称为该随机试验的样本空间。一般用大写字母S表示\n\n常见例子：\n\n*抛两枚硬币，考察哪枚硬币正面朝上，样本空间包含下面四种结果：\n\nS = {(H,H),(H,T),(T,H),(T,T)}\n\n(H,H)表示两枚硬币都是正面朝上,(H,T)表示第一枚正面朝上，第二枚反面朝上，其他类推。\n\n*新生婴儿性别，所有可能结果构成样本空间\n\nS = {G,B}\n\nG--女孩，B--男孩\n\n***事件**\n\n样本空间的任一子集E称为事件，事件就是有实验某些可能结果组成的**集合**\n\n例如\n\n1.抛两枚硬币，第一枚硬币正面朝上有两种可能结果(H,H),(H,T).这两个可能的结果构成“第一枚硬币正面朝上”这个事件:\n\n\n\nE = {(H,H),(H,T)}\n\n\n2.新生婴儿是个女孩这个结果构成事件：\n\nE={G}\n\n实验的结果包含在E中，就称为**事件发生。**\n\n***随机事件**\n\n样本空间S的子集E叫做随机事件，简称事件，随机事件可能出现也可能不出现。比如新生婴儿是女孩这个事件就是随机的，硬币正面朝上也是随机的。\n\n***必然事件**\n\n每次试验中一定出现的事件，比如掷一颗骰子，点数大于0，小于7这个事件是必然的。\n\n***不可能事件**\n\n每次试验中不可能出现的事件，比如掷一颗骰子，点数大于6这个事件是不可能发生的。\n\n***基本事件**\n\n样本空间中每个结果称为基本事件，基本事件不能再分解。\n\n\n\n\n\n\n\n\n\n\n**概率**\n\n假设有一样本空间为S 的试验，它在相同条件下可重复进行，对应样本空间中的事件E，记n(E)为n次重复试验中事件E发生的频率（次数），那么该事件发生的概率P(E)定义为：\n\n$$P(E)=\\lim_{n \\rightarrow+\\infty} \\frac{n(E)}{n}$$\n\n事件E的概率P(E)要满足概率的三个公理：\n\n公理1：\n$$0\\leq P(E) \\leq 1$$\n$$**即任何事件E的概率在0到1之间**$$\n\n公理2：\n$$P(S)= 1$$\n$$**样本空间作为必然发生的事件，其概率为1**$$\n\n公理3：\n\n$$**对任意一列互不相容的事件E_1,E_2,...(如果i≠j，则E_iE_j=\\emptyset，两事件不能同时发生),\\\\至少一件事件发生的概率等于各事件发生概率和,有 \\\\P\\left(\\bigcup_{i=1}^\\infty E_i\\right) = \\sum_{i=1}^\\infty P(E_i)**$$\n\n\n\n\n\n\n```python\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats import mode\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set(style='white',context='notebook',palette='muted')\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv('train.csv')\ncopy = train.sample(200)\ncopy\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>618</th>\n      <td>619</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Becker, Miss. Marion Louise</td>\n      <td>female</td>\n      <td>4.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>230136</td>\n      <td>39.0000</td>\n      <td>F4</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>515</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Coleff, Mr. Satio</td>\n      <td>male</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349209</td>\n      <td>7.4958</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>102</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Petroff, Mr. Pastcho (\"Pentcho\")</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349215</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>879</th>\n      <td>880</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n      <td>female</td>\n      <td>56.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>11767</td>\n      <td>83.1583</td>\n      <td>C50</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>295</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Mineff, Mr. Ivan</td>\n      <td>male</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349233</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>573</th>\n      <td>574</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Kelly, Miss. Mary</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14312</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>415</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Sundman, Mr. Johan Julian</td>\n      <td>male</td>\n      <td>44.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O 2. 3101269</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>219</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Bazzani, Miss. Albina</td>\n      <td>female</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11813</td>\n      <td>76.2917</td>\n      <td>D15</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>436</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Carter, Miss. Lucile Polk</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>113760</td>\n      <td>120.0000</td>\n      <td>B96 B98</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Nicola-Yarred, Miss. Jamila</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2651</td>\n      <td>11.2417</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 12 columns</p>\n</div>\n\n\n\n\n```python\n#以泰坦尼克数据为例 \n#随机抽取200名乘客数据，计算男女乘客的概率\nmale = (copy.Sex=='male').sum() / len(copy)\nmale\n\n```\n\n\n\n\n    0.59\n\n\n\n\n```python\nfemale = (copy.Sex=='female').sum() / len(copy)\nfemale\n```\n\n\n\n\n    0.41\n\n\n\n\n```python\ncount = copy['Sex'].value_counts()\nplt.bar(count.index,height=count)\n#可见随机抽取的人数中男性比例高于女性\n```\n\n\n\n\n    <BarContainer object of 2 artists>\n\n\n\n\n![png](output_5_1.png)\n\n","tags":["随机事件"],"categories":["概率"]},{"title":"品质数据处理","url":"/2021/09/22/品质数据处理/","content":"\n\n**品质数据（非数值数据）的处理**\n\n品质数据是用文字表示的，主要做分类处理，品质数据又分为分类数据和顺序数据。\n\n分类数据是说明事物类别的一个名称，例如：水果类，蔬菜类，肉类。\n\n顺序数据是说明事物有序类别的一个名称，例如：服务等级分为优，良，中。学历分为大专，本科，研究生。等等\n\n\n\n\n```python\n#以泰坦尼克数据为例\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#数据在kaggle官网下载，注册一个账号就行\ndata = pd.read_csv('train.csv')\ndf = data.sample(200)\n\ndf\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>50</th>\n      <td>51</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Panula, Master. Juha Niilo</td>\n      <td>male</td>\n      <td>7.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3101295</td>\n      <td>39.6875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>272</th>\n      <td>273</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Mellinger, Mrs. (Elizabeth Anne Maidment)</td>\n      <td>female</td>\n      <td>41.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>250644</td>\n      <td>19.5000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>285</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Smith, Mr. Richard William</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113056</td>\n      <td>26.0000</td>\n      <td>A19</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>143</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Hakkarainen, Mrs. Pekka Pietari (Elin Matilda ...</td>\n      <td>female</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>STON/O2. 3101279</td>\n      <td>15.8500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>768</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Mangan, Miss. Mary</td>\n      <td>female</td>\n      <td>30.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>364850</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>283</td>\n      <td>0</td>\n      <td>3</td>\n      <td>de Pelsmaeker, Mr. Alfons</td>\n      <td>male</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>345778</td>\n      <td>9.5000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>863</th>\n      <td>864</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2</td>\n      <td>CA. 2343</td>\n      <td>69.5500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>492</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Windelov, Mr. Einar</td>\n      <td>male</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/OQ 3101317</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>638</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Collyer, Mr. Harvey</td>\n      <td>male</td>\n      <td>31.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>C.A. 31921</td>\n      <td>26.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>317</th>\n      <td>318</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Moraweck, Dr. Ernest</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29011</td>\n      <td>14.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 12 columns</p>\n</div>\n\n\n\n\n```python\n#查看购买1,2,3类等级票各有多少人\ndf['Pclass'].value_counts()\n```\n\n\n\n\n    3    112\n    2     46\n    1     42\n    Name: Pclass, dtype: int64\n\n\n\n\n```python\n#饼图查看频数\npclass = df['Pclass'].value_counts()\nlabels=['3','2','1']\nfig = plt.figure()\nplt.pie(pclass,labels=labels,autopct='%1.2f%%')\nplt.title(\"Pie Chart\")\n```\n\n\n\n\n    Text(0.5,1,'Pie Chart')\n\n\n\n\n![png](output_3_1.png)\n\n\n\n```python\n#根据登录港口 查看各等级票的人数  按升序排列\ns = df['Pclass'][df['Embarked']=='S'].value_counts().sort_index(ascending = True)#S港口登录的人\nprint(s)\nc = df['Pclass'][df['Embarked']=='C'].value_counts().sort_index(ascending = True)#C港口登录的人\nprint(c)\n#可见C港登录的人中 1类票人最多 也就是这个港口登录的有钱人比较多\n\n```\n\n    1    24\n    2    42\n    3    86\n    Name: Pclass, dtype: int64\n    1    18\n    2     3\n    3    11\n    Name: Pclass, dtype: int64\n    \n\n\n```python\n#条形图展示 各港口的票类型频数\nsns.catplot('Pclass',col='Embarked',kind='count',data=data,height=4)\n```\n\n\n\n\n    <seaborn.axisgrid.FacetGrid at 0x220e3ec8748>\n\n\n\n\n![png](output_5_1.png)\n\n\n\n```python\n #男士，女士生存率 Survived=0代表死亡  Survived=1代表生存\nsns.catplot('Sex',col='Survived',kind='count',data=data,height=4)\n```\n\n\n\n\n    <seaborn.axisgrid.FacetGrid at 0x220e3c7c860>\n\n\n\n\n![png](output_6_1.png)\n\n\n\n```python\n#使用交叉表统计分类频数 margins=True 是添加行列合计功能\n#使用交叉表比单独使用value_counts 表达更清晰\npd.crosstab(df['Pclass'],df['Embarked'],margins=True)\n#pd.crosstab(df['Pclass'],df['Embarked']).applay(lambda row：row/row.sum())\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Embarked</th>\n      <th>C</th>\n      <th>Q</th>\n      <th>S</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>0</td>\n      <td>24</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>42</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>15</td>\n      <td>86</td>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>32</td>\n      <td>16</td>\n      <td>152</td>\n      <td>200</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n#crosstab更高级的用法\n#考试是否及格  Y--及格  N--不及格\np = np.array([\"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\",\"N\", \"N\", \"Y\", \"Y\", \"Y\"], dtype=object)\n\n#年级 1年级  2年级\ng = np.array([\"1\", \"1\", \"1\", \"2\", \"1\", \"1\",\"1\", \"2\", \"2\", \"2\", \"1\"], dtype=object)\n\n#考试科目  数学M 语文C\nc = np.array([\"M\", \"M\", \"C\", \"M\", \"M\", \"C\",\"C\", \"M\", \"C\", \"C\", \"C\"],dtype=object)\n\npd.crosstab(p, [g, c], rownames=[u'是否及格'], colnames=[u'年级', u'科目'],margins=True)\n#可见 一年级为例 数学2个及格 ，1个不及格   语文2个及格，2个不及格\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>年级</th>\n      <th colspan=\"2\" halign=\"left\">1</th>\n      <th colspan=\"2\" halign=\"left\">2</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>科目</th>\n      <th>C</th>\n      <th>M</th>\n      <th>C</th>\n      <th>M</th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>是否及格</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>N</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Y</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n#查看及格人数比例\nproportion = pd.crosstab(p, [g, c], rownames=[u'是否及格'], colnames=[u'年级', u'科目']).apply(lambda row: row/row.sum(),axis=1)\nproportion\n#一年级语文不及格人数占总不及格人数的1/2 数学不及格人数占总不及格人数1/4\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>年级</th>\n      <th colspan=\"2\" halign=\"left\">1</th>\n      <th colspan=\"2\" halign=\"left\">2</th>\n    </tr>\n    <tr>\n      <th>科目</th>\n      <th>C</th>\n      <th>M</th>\n      <th>C</th>\n      <th>M</th>\n    </tr>\n    <tr>\n      <th>是否及格</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>N</th>\n      <td>0.500000</td>\n      <td>0.250000</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>Y</th>\n      <td>0.285714</td>\n      <td>0.285714</td>\n      <td>0.285714</td>\n      <td>0.142857</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n#查看及格人数比率 即百分比 乘以100就行\npercentage = pd.crosstab(p, [g, c], rownames=[u'是否及格'], colnames=[u'年级', u'科目']).apply(lambda row: row/row.sum() *100,axis=1)\npercentage\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>年级</th>\n      <th colspan=\"2\" halign=\"left\">1</th>\n      <th colspan=\"2\" halign=\"left\">2</th>\n    </tr>\n    <tr>\n      <th>科目</th>\n      <th>C</th>\n      <th>M</th>\n      <th>C</th>\n      <th>M</th>\n    </tr>\n    <tr>\n      <th>是否及格</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>N</th>\n      <td>50.000000</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>Y</th>\n      <td>28.571429</td>\n      <td>28.571429</td>\n      <td>28.571429</td>\n      <td>14.285714</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n**顺序数据的整理与图示**\n\n\n\n```python\n#还是以登录港口人数作为统计案例，严格来说登录港口不算是顺序数据。\n#但是这里结合登录人数可以看出它隐含了一些假设，港口登录的人数是有序的\n#查看顺序数据的累积频数\ndesc = data['Embarked'].value_counts()#默认降序排列\n\nprint(desc)\n\nasc = desc.sort_values(ascending=True)\nbase = [100,400,650]\nplt.figure(figsize=(9,3))\nplt.subplot(121)\n#降序排列\nplt.plot(desc,base,c='green')\nplt.subplot(122)\n#升序排列\nplt.plot(asc,base,c='red')\nplt.show()\n```\n\n    S    644\n    C    168\n    Q     77\n    Name: Embarked, dtype: int64\n    \n\n\n![png](output_12_1.png)\n\n\n\n```python\n\n```\n","tags":["数据预处理"],"categories":["统计"]},{"title":"抽样误差","url":"/2021/09/22/sampling/","content":"数据误差：\n\n**1.抽样误差：**\n\n*样本是总体的子集\n\n*在概率抽样中，由抽样随机性引起的样本结果与总体真值之间的误差。\n\n*抽样误差不是针对某个具体样本的检测结果与总体真实结果的差异而言，而是描述所有样本可能的结果与总体真值之间的平均差异。\n\n例如：\n要测一批产品非优质品率，这里一批产品为总体，从中随机抽取产品数量相同的多个样本，\n假设总体真正的非优质品率为30%，而有95%的样本非优品率会落在27.2%--32.8%之间（涉及到中心极限定理）。\n\n30%-2.8%=27.2%，30%+2.8%=32.8%  这个$^+_ -2.8$%的误差就是抽样误差，是由抽样随机性带来的\n\n引起抽样误差原因：\n\n*样本量越大，抽样误差越小，反之样本小，抽样误差大\n\n*总体变异性越大，即每个产品之间差异越大，抽样误差越大，反之各单位产品越相似，抽样误差越小。\n\n<br/>\n\n**2.非抽样误差：**\n\n*非抽样误差是相对抽样误差而言，是指除抽样误差外，由其他原因引起的样本观察结果与总体真值之间的差异。\n\n*非概率抽样也会产生非抽样误差\n\n\n\n\n\n\n\n","tags":["数据误差"],"categories":["统计"]},{"title":"两个总体均值之差区间估计--独立样本","url":"/2021/09/22/两个总体均值之差区间估计/","content":"**两个总体参数的区间估计**\n\n两个总体均值之差的区间估计----独立样本\n\n**1.大样本的估计**\n\n如果两个样本是从两个总体中独立抽取的，假设是A,B两个总体，A中抽取样本与B中抽取样本相互独立，则称为独立样本\n\n两个样本均值之差抽样分布服从期望：$E(\\bar{X_1}-\\bar{X_2}) = E(\\bar{X_1})-E(\\bar{X_2}) = \\mu_{1}-\\mu_{2}$\n,方差为$D(\\bar{X_1}) + D(\\bar{X_2}) = \\frac{\\sigma_{1}^2}{n_1} +\\frac{\\sigma_{2}^2}{n_2}$的正态分布。\n\n\n两个总体方差$\\sigma^2$和$\\sigma^2$都已知时，两个总体均值之差$\\mu_{1}-\\mu_{2}$在1-α置信水平下的置信区间为：\n$$(\\bar{x_1} - \\bar{x_2}) \\pm z_{\\alpha/2}\\sqrt{ \\frac{\\sigma_{1}^2}{n_1} +\\frac{\\sigma_{2}^2}{n_2}}$$ \n\n两个总体方差$\\sigma^2$和$\\sigma^2$未知时，两个总体均值之差$\\mu_{1}-\\mu_{2}$在1-α置信水平下的置信区间为：\n$$(\\bar{x_1} - \\bar{x_2}) \\pm z_{\\alpha/2}\\sqrt{ \\frac{s_{1}^2}{n_1} +\\frac{s_{2}^2}{n_2}}$$ \n\n\n\n例子：估计两所中学学生高考英语平均分数之差，两所中学独立抽样数据：\n\n中学1： $n_1$=46,$\\bar{x_1}$=86,$s_1$=5.8\n\n中学2： $n_2$=33,$\\bar{x_2}$=78,$s_2$=7.2\n\n建立两所中学高考英语平均分数之差的95%置信区间\n\n因为这里只强调平均分的差异，不强调某一方检验，查表得双侧临界值为$z_{\\alpha/2}$=1.96。\n\n\n\n\n```python\nimport numpy as np\nimport pandas as pd\ns1 = [46,86,5.8]\ns2 = [33,78,7.2]\ntable = pd.DataFrame([s1,s2],index=['中学1','中学2'],columns=['人数','均值','标准差']).T\ntable  \n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>中学1</th>\n      <th>中学2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>人数</th>\n      <td>46.0</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>均值</th>\n      <td>86.0</td>\n      <td>78.0</td>\n    </tr>\n    <tr>\n      <th>标准差</th>\n      <td>5.8</td>\n      <td>7.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n#根据公式计算\nfrom scipy import stats \n#由于方差未知，所以用样本方差代替,上面第二个式子\nvar = np.sqrt(5.8**2 /46 + 7.2**2 / 33)\n#下界\nlow = (86-78)-1.96*var\n#上界\nupper = (86-78)+1.96*var\nprint([low,upper])\n#所以说两小学英语平均分之差的95%置信区间为5.02---10.97分\n#或者说有%95的把握，英语平均分差值在5.02---10.97之间\n```\n\n    [5.0260828615704405, 10.97391713842956]\n    \n\n**2.小样本的估计**\n两个样本都为小样本的情况估计两个总体均值之差，有两个假设前提：\n\n1 两个总体服从正态分布\n\n2 两个随机样本独立抽自两个总体\n\n\n***\n\n当两个总体方差未知但相等，即$\\sigma_1^2$\n\n\n\nstats.norm.interval(0.95)\n","tags":["参数估计"],"categories":["统计"]},{"title":"总体均值区间估计","url":"/2021/09/22/总体均值区间估计/","content":"\n总体均值区间估计\n\n有一大批糖果，从中随机抽取16袋，称得质量（单位：g）如下：\n\n506 508 499 503 504 510 497 512\n\n514 505 493 496 506 502 509 496\n\n设袋装糖果质量近似服从正态分布，试求总体均值$\\;\\mu$的置信度为0.95的置信区间。\n\n假设与条件:\n\n1.糖果质量近似服从正态分布。\n\n2.随机取16袋样本，置信度为0.95，构造估计量的样本数小于30，根据经验为小样本,并且总体方差未知。\n\n要用t分布建立总体均值$\\;\\mu$的置信区间\n\n解：总体均值$\\mu$在1-$\\alpha$置信水平下的置信区间为$\\big(\\overline{X} \\pm \\frac{S}{\\sqrt{n}}t_{\\alpha/2}(n-1)\\big) $\n\n$\\overline{X}$--样本均值，S为样本标准差，n为样本容量。\n\n显著水平$\\alpha$=0.05,$\\alpha/2$=0.025,自由度n-1=15，查t分布表得$t_{\\alpha/2}(n-1)$=2.1315\n\n\n\n\n\n\n\n```python\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nx = [506 ,508 ,499 ,503 ,504 ,510 ,497 \n     ,512 ,514 ,505 ,493 ,496 ,506 ,502 ,509 ,496]\n\n#t分布建立置信区间函数\ndef t_interval(x,conf,df):\n    alpha = 1-conf#\n    n = df-1#自由度\n        \n    std = np.std(x,ddof=1)#标准差 ddof=1 无偏估计\n    mu = np.mean(x)#均值\n    t_score = stats.t.isf(alpha/2,df=n)#t分布临界值\n   \n    low = mu-(std/np.sqrt(df))*t_score #这里std/np.sqrt(df)相当于标准误\n    upper = mu+(std/np.sqrt(df))*t_score\n    \n    return [low,upper]\n\nt_interval(x,0.95,16)\n\n#有95%的样本糖果均值所构造的置信区间会包括总体糖果的质量均值\n#或者说95%把握认为总体糖果质量均值落在置信区间中\n```\n\n\n\n\n    [500.44510746243924, 507.05489253756076]\n\n\n\n\n```python\n#使用scipy 求置信区间\nsem = stats.sem(x)#样本标准误差\nmu = np.mean(x)#均值\nci = stats.t.interval(alpha=0.95,df=len(x)-1,loc=mu,scale=sem)\nci\n```\n\n\n\n\n    (500.44510746243924, 507.05489253756076)\n\n\n\n\n","tags":["参数估计"],"categories":["统计"]},{"title":"总体均值与方差区间估计","url":"/2021/09/22/总体方差与均值区间估计/","content":"分别使用金球和铂球测定引力常数(单位：10-11m3×kg-1×s-2)．\n\n   (1)用金球测定观测值6.683，6.681，6.676，6.678，6.679,6.672;\n\n   (2)用铂球测定观测值6.661，6.661，6.667，6.667，6.664.设测定值总体为N(u，σ2)，其中u、σ2均未知．试就(1)、(2)两种情况分别求u的置信度为0.9的置信区间，并求σ2的置信度为0.9的置信区间\n\n**1.求u的置信度为0.9的置信区间：**\n\n由于是小样本抽样，并且总体均值与方差未知，使用t分布建立总体均值$\\;\\mu$的置信区间\n\n总体均值$\\mu$在1-$\\alpha$置信水平下的置信区间为$\\big(\\overline{X} \\pm \\frac{S}{\\sqrt{n}}t_{\\alpha/2}(n-1)\\big) $\n\n这里1-$\\alpha$=0.9,$\\alpha$=0.1,$\\alpha/2$=0.05,\n\n金球样本自由度为n1-1=5,铂球样本自由度为n2-1=4\n\n\n\n\n\n\n\n```python\nx1 = [6.683,6.681,6.676,6.678,6.679,6.672]\nx2 = [6.661,6.661,6.667,6.667,6.664]\n#使用之前t_interval函数 建立置信区间\nx1_ci=t_interval(x1,0.9,6)\nx2_ci=t_interval(x2,0.9,5)\nprint('用金球测定时,μ的置信区间是{}'.format(x1_ci))\nprint('用铂球测定时,μ的置信区间是{}'.format(x2_ci))\nprint('###############')\n\n################\n\n#使用scipy库计算#\nx1_sem = stats.sem(x1)\nx2_sem = stats.sem(x2)\n\nx1_df = len(x1)-1\nx2_df=len(x2)-1\n\nx1_mu=np.mean(x1)\nx2_mu=np.mean(x2)\n\nx1_ci=stats.t.interval(alpha=0.9,df=x1_df,loc=x1_mu,scale=x1_sem)\nx2_ci=stats.t.interval(alpha=0.9,df=x2_df,loc=x2_mu,scale=x2_sem)\nprint('用金球测定时,μ的置信区间是{}'.format(x1_ci))\nprint('用铂球测定时,μ的置信区间是{}'.format(x2_ci))\n\n```\n\n    用金球测定时,μ的置信区间是[6.67498413748818, 6.681349195845152]\n    用铂球测定时,μ的置信区间是[6.66113982740759, 6.6668601725924095]\n    ###############\n    用金球测定时,μ的置信区间是(6.67498413748818, 6.681349195845152)\n    用铂球测定时,μ的置信区间是(6.66113982740759, 6.6668601725924095)\n    \n\n**2.求σ2的置信度为0.9的置信区间**\n与第一个问题不同，这是要求方差的置信区间，方差与样本差异有关，而与样本量关系不大。\n\n样本方差服从自由度为n-1的卡方分布（证明要看数理统计教材），所以直接用总体方差的区间估计方法：\n$$\\frac{(n-1)s^2}{\\chi_{\\alpha/2}^2} \\leq \\sigma^2 \\leq \\frac{(n-1)s^2}{\\chi_{1-\\alpha/2}^2} $$\n\n这里$S^2$是样本方差，$\\chi_{\\alpha/2}^2$， $\\chi_{1-\\alpha/2}^2$是卡方分布临界值\n\n\n\n\n\n```python\nx1 = [6.683,6.681,6.676,6.678,6.679,6.672]\nx2 = [6.661,6.661,6.667,6.667,6.664]\ndef chi_interval(x,conf,n):\n    #std = np.std(x1,ddof=1)\n    var  =np.var(x1,ddof=1)#方差\n    alpha = 1-conf\n    df = n-1\n    score_0 = stats.chi2.isf(alpha/2,df)#下界卡方分布临界值\n    score\n```\n\n\n```python\nx1 = [6.683,6.681,6.676,6.678,6.679,6.672]\nx2 = [6.661,6.661,6.667,6.667,6.664]\ndef chi_interval(x,conf,n):\n    #std = np.std(x1,ddof=1)\n    var  =np.var(x,ddof=1)#方差\n    alpha = 1-conf\n    df = n-1\n    score_0 = stats.chi2.isf(alpha/2,df)#下界卡方分布临界值\n    score_1 = stats.chi2.isf(1-alpha/2,df)#上界卡方分布临界值\n    #或者使用stats.chi2.interval(0.9,5)求临界值\n    #score=stats.chi2.interval(conf,df)\n   # print(score)(1.145476226061769, 11.070497693516351)\n    #score_0=score[1]\n    #score_1=score[0]\n    \n    \n\n    low = df*var/score_0\n    upper = df*var/score_1\n    return [low,upper]\n\nx1_ci = chi_interval(x1,0.9,6)\nx2_ci = chi_interval(x2,0.9,5)\nprint('用金球测定时,σ2的置信区间是{}'.format(x1_ci))\nprint('用铂球测定时,σ2的置信区间是{}'.format(x2_ci))\n```\n\n    用金球测定时,σ2的置信区间是[6.759708136442946e-06, 6.532945130656948e-05]\n    用铂球测定时,σ2的置信区间是[3.7943748035426858e-06, 5.065264373908214e-05]\n    \n","tags":["参数估计"],"categories":["统计"]},{"title":"报童模型","url":"/2021/09/22/报童模型/","content":"\n**报童售报模型**\n\n基本问题是报童每天用每份2元价格进一批报纸，以4元零售，当天没卖掉的报纸退回，得到每份1元的补偿，报童每天应该进多少报纸使日均利润最高。\n\n\n由于真实情况供应链模型比较复杂，要考虑很多因素，比如供货商与零售商决策之间的影响，价格对市场的影响等。还有这个问题中报纸是个易逝品，假设当天报纸没卖完就会损耗，因为没人看前一天的报纸。\n\n所以这里的模型都是在最理想的情况下得到的。\n\n***\n\n1.离散型需求下的报童模型：\n\n我们将每天报纸需求看做离散随机变量，就是我们假设以需求量为单位，每100份报纸为1个单位，每\n\n种需求量对应一个概率\n\n\n| 需求量/单位 r | 0 | 1 | 2 | 3 | 4 | 5 |\n|  ----  | ----  |----  |----  |----  |----  |----  |\n| 概率/分布  f(r)  | 0 | 0.1 | 0.3 | 0.4 | 0.1 | 0.1 |\n\n建模：\n\n定义：需求量取值为r时的概率为f(r)(r=0,1,2,..n),\n\n报童每天进报纸数量为q单位,\n\n报童每天售出1个单位报纸获利记为$s_{1}$,\n\n剩余退回1单位报纸的损失为$s_{2}$,\n\n每天利润与进货量(q)和需求量(r)是相关的，定义利润函数s(r,q)\n\n每天利润分两种情况考虑:\n\n*全部卖完,供不应求，利润为$q \\times s_{1}$\n\n*没卖完，供大于求,则损失为$(q-r)\\times s_{2}$，获利为卖出量减损失量$ r \\times s_{1} - (q-r)\\times s_{2}$\n\n***\n\n\n得利润分布函数：$$ s(r,q) = \\begin{cases}q \\times s_{1} ,r > q \\\\ r \\times s_{1} - (q-r)\\times s_{2}, r\\leq q\\end{cases} $$\n\n或者 $$ s(r,q) = \\begin{cases}q \\times s_{1} ,r \\geq q \\\\ r \\times s_{1} - (q-r)\\times s_{2}, r< q\\end{cases} $$\n\n****\n\n从上面利润分布函数看，由于每天订购量q已经确定，于是每日的利润是随需求量r变化的，需求量r又对应不同的概率，同时为离散随机变量，那么每天不同需求量下,对应的利润s(r,q)也可看做是离散随机变量.\n\n根据离散型随机变量期望的定义，可以确定每日的平均利润为：\n$$\\sum_{r=0}^ns(r,q)f(r) = \\sum_{r=0}^q[s_1r-s_2(q-r)]f(r)+\\sum_{r=q+1}^n s_1 q f(r), n=5$$\n\n因为利润根据需求量r,分布在两个区间内,r > q 和$r\\leq q $,所以总利润的平均为两个区间的平均和\n\n上式也可以理解为每种需求量下利润的平均\n\n\n\n\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n#plt.rcParams['font.sans-serif'] = ['SimHei'] # 步骤一（替换sans-serif字体）\n#plt.rcParams['axes.unicode_minus'] = False   # 步骤二（解决坐标轴负数的负号显示问题）\n\n#需求量分布函数\ndef func(r):\n    p = [0,0.1,0.3,0.4,0.1,0.1]\n    return p[r]\n\ndef e(q):\n    pro1=0\n    pro2=0\n    n = 5  #这个案例中需求量最大值\n    \n    #供过于求情况的利润期望 r<=q\n    for r in range(0,q+1):\n        pro1 += (200*r-100*(q-r))*func(r)\n    \n    #供不应求情况的利润期望 r>q\n    for r in range(q+1,n+1):\n        pro2 += 200*q*func(r)\n        \n    pro = pro1+pro2\n    \n    return pro\n\ndef marginal():\n    for q in range(1,4):\n        incre = e(q+1)-e(q)\n        print(incre)\n\n\ndef show(x,y):\n    \n    font = {'family': 'SimHei',\n        'color':  'black',\n        'weight': 'normal',\n        'size': 16,\n        }\n\n    plt.stem(x,y) \n    plt.tick_params(labelsize=12)\n    plt.xlabel('订购量q',fontdict=font)\n    plt.ylabel('利润期望值',fontdict=font)\n    \n#确定订购量q 从1开始依次增加\ndef main():\n    y=[]\n    x=[]\n    marginal()\n    for q in range(1,6):\n        y.append(e(q))\n        x.append(q)\n    \n    show(x,y)\n        \n    \nmain()\n\n```\n\n    170.0\n    80.0\n    -40.0\n    \n\n\n![png](output_1_1.png)\n\n\n连续型需求下的模型：\n假设报童每售出一份报纸获利2元,记为s1=2.剩余退回损失为1元，记为s2=1\n\n前面假设需求量为离散型随机变量，当报纸需求量很大时，用离散随机变量表示概率分布和求期望会很麻烦。\n\n现在根据以往统计资料及经验，把需求量看做连续型随机变量，假设报纸需求量大致服从正态分布，设其平均值为260，标准差为50，即需求量服从N(260,50^2)的正态分布。\n\n\n\n建模：\n\n由于是连续型随机变量，就用概率密度p(r)来表示需求量。\n\n同时连续型随机变量不考虑某一点的概率，而是考虑随机变量落在区间的概率，所以用p(r)dr替代离散模型中的f(r)。\n\n可以得日均利润公式为$$E(q) = \\int_{-\\infty}^q [s_1r - s_2(q-r)]p(r)dr + \\int_{q}^{\\infty}s_1qp(r)dr$$\n\n问题转变成了求函数最大值的问题，这里就是要求最优采购量q,使得日均利润E(q)最大化\n\n对q求导数并令$\\frac{dE}{dq} =0$:\n\n\n$E(q) = \\int_{-\\infty}^q [s_1r - s_2(q-r)]p(r)dr + \\int_{q}^{\\infty}s_1qp(r)dr$ \n\n= $\\int_{-\\infty}^qs_1rp(r)dr$ - $\\int_{-\\infty}^qs_2qp(r)dr$ +$\\int_{-\\infty}^qs_2rp(r)dr$ +$\\int_{q}^{\\infty}s_1qp(r)dr$  \n\n= $s_1r\\int_{-\\infty}^qp(r)dr$ - $s_2q\\int_{-\\infty}^qp(r)dr$ +$s_2r\\int_{-\\infty}^qp(r)dr$ +$s_1q\\int_{q}^{\\infty}p(r)dr$  \n\n***\n\n$\\frac{dE(q)}{dq} = s_1qp(q) - s_2\\big(\\int_{-\\infty}^qp(r)dr + qp(q)\\big)+s_2qp(q) + s_1(\\int_{q}^{\\infty}p(r)dr-qp(q))  \\big)$ \n\n=$s_1qp(q) - s_2\\int_{-\\infty}^qp(r)dr - s_2qp(q)+s_2qp(q) + s_1\\int_{q}^{\\infty}p(r)dr-s_1qp(q) $ \n\n=$ s_1\\int_{q}^{\\infty}p(r)dr - s_2\\int_{-\\infty}^qp(r)dr$\n***\n\n因为概率密度性质：$\\int_{-\\infty}^{\\infty} p(r)dr = 1$ ,得$s_1\\int_{q}^{\\infty}p(r)dr = s_1(1 - \\int_{-\\infty}^{q}p(r)dr) $\n\n最终$\\frac{dE(q)}{dq} = s_1 - (s_1+s_2)\\int_{-\\infty}^{q}p(r)dr$ = 0\n\n然后要证明有最大值，继续求二阶导数：\n\n$\\frac{d^2E(q)}{dq^2}$ <0,并且q为驻点，所以在$\\frac{dE(q)}{dq} = 0$时E(q)有最大值\n\n\n***\n\n可以记r的分布函数为$F(q)=\\int_{-\\infty}^{q}p(r)dr$，F(q)也是累积分布函数\n\n\n得到：$\\frac{dE(q)}{dq} = s_1 - (s_1+s_2)\\int_{-\\infty}^{q}p(r)dr$\n\n=$s_1 - (s_1+s_2)F(q)$ = 0\n\n由前面的条件s1=2,s2=1时,\n$F(q) = \\frac{s_1}{s_1+s_2} = \\frac{2}{3}$\n***\n\n\n\n因为$\\frac{dE(q)}{dq} = s_1 - (s_1+s_2)F(q) =0$时，E(q)有最大解,\n所以相当于$F(q) = \\frac{s_1}{s_1+s_2} $时，E(q)有最大解.\n\n由累积分布函数与密度函数的关系可得：\n\n$F(q) = P\\{R\\in(-\\infty,q)\\}=\\int_{-\\infty}^{q}p(r)dr = \\frac{s_1}{s_1+s_2} =\\frac{2}{3}$,这个式子的意思是：有一个q值，使得r 属于区间$(-\\infty,q)$的概率等于$\\frac{2}{3}$。\n\n换句话说,就是这个q值，使得分布函数F(q)=$\\frac{2}{3}$时，E(q)有最大解,现在就是要求出这个q值，本案例中就是每天进货量。\n\n***\n\n由于前面假设r是服从正态分布的，于是$F(q)= \\int_{-\\infty}^{q}p(r)dr$\n\n$= \\frac{1}{\\sigma\\sqrt{2π}}\\int_{-\\infty}^{q}e^{-(r^{,}-\\mu^{2})/(2\\sigma^{2}))}dr^{,}$\n\n$=\\frac{1}{2}\\big[ 1+  erf\\big( \\frac{q-\\mu}{\\sigma\\sqrt{2}}  \\big) \\big] = \\frac{2}{3}$\n\n下面根据公式，使用程序求解：\n\n\n\n\n\n```python\nfrom scipy import stats\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n#求分位点  #分布函数为0.6时对应x轴的点\n#逆累积分布：通过概率求分位点。\n\n#scipy求分位点\npoint = stats.norm(260,50).ppf(0.666)\npoint\n\n```\n\n\n\n\n    281.4447252037101\n\n\n\n结果可见当报童每天进281份报纸使可以获得最高利润\n\n需要将q值带入$E(q) = \\int_{-\\infty}^q [s_1r - s_2(q-r)]p(r)dr + \\int_{q}^{\\infty}s_1qp(r)dr$公式,求出最高利润值\n\n由假设知道r服从正态分布$N(260,50^2)$,\n\n$p(r)= \\frac{1}{\\sigma\\sqrt{2π}}e^{-(r^{,}-\\mu^{2})/(2\\sigma^{2})}dr$\n\n对E(q)使用变量代换求积分即可\n\n令$u=\\frac{r-\\mu}{\\sigma \\sqrt{2}}$\n\n则$du = \\frac{dr}{\\sigma\\sqrt{2}},  r=u\\sigma\\sqrt{2}+\\mu$ \n\n积分上限 =$\\frac{q-\\mu}{\\sigma \\sqrt{2}}$,为方便计算暂时用q替代\n\n$E(q)= \\int_{-\\infty}^q [s_1r - s_2(q-r)]p(r)dr + \\int_{q}^{\\infty}s_1qp(r)dr$ \n\n=$s_1\\int_{-\\infty}^qrp(r)dr$ - $s_2q\\int_{-\\infty}^qp(r)dr$ +$s_2\\int_{-\\infty}^qrp(r)dr$ +$s_1q(1-\\int_{-\\infty}^{q}p(r)dr)$  \n***\n\n先分开计算\n\n$s_1\\int_{-\\infty}^qrp(r)dr$ = $s_1\\frac{1}{\\sqrt{\\pi}}\\int_{-\\infty}^q(\\sqrt{2}\\sigma u +\\mu) e^{-u^2}du$\n\n= $s_1(\\frac{\\sigma \\sqrt{2}}{\\sqrt{\\pi}} \\int_{-\\infty}^q u e^{-u^2}du+\\frac{\\mu}{\\sqrt{\\pi}}\\int_{-\\infty}^q e^{-u^2}du )$\n\n=$-s_1 \\frac{\\sqrt{2}\\sigma e^{-q^2}}{2\\sqrt{\\pi}} -s_1\\frac{\\mu}{2\\sqrt{\\pi}}e^{-q^2}$\n\n***\n类似的\n\n$s_2\\int_{-\\infty}^qrp(r)dr$ = $s_2\\frac{1}{\\sqrt{\\pi}}\\int_{-\\infty}^q(\\sqrt{2}\\sigma u +\\mu) e^{-u^2}du$\n\n=$-s_2 \\frac{\\sqrt{2}\\sigma e^{-q^2}}{2\\sqrt{\\pi}} -s_2\\frac{\\mu}{2\\sqrt{\\pi}}e^{-q^2}$\n***\n\n$s_2q\\int_{-\\infty}^qp(r)dr = -s_2q\\frac{1}{2\\sqrt{\\pi}}e^{-q^2}$\n***\n$s_1q(1-\\int_{-\\infty}^{q}p(r)dr)$  =$s_1q+s_1q\\frac{1}{2\\sqrt{\\pi}}e^{-q^2}$\n\n\n则原式E(q) = $-s_1 \\frac{\\sqrt{2}\\sigma e^{-q^2}}{2\\sqrt{\\pi}} -s_1\\frac{\\mu}{2\\sqrt{\\pi}}e^{-q^2}+s_2q\\frac{1}{2\\sqrt{\\pi}}e^{-q^2} -s_2 \\frac{\\sqrt{2}\\sigma e^{-q^2}}{2\\sqrt{\\pi}} +s_2\\frac{\\mu}{2\\sqrt{\\pi}}e^{-q^2}+s_1q+s_1q\\frac{1}{2\\sqrt{\\pi}}e^{-q^2}$ \n\n由于$F(q)=\\int_{-\\infty}^qp(r)dr = -\\frac{1}{2\\sqrt{\\pi}}e^{-q^2}$，\n\n并且由P(q)=$\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(q^{,}-\\mu^{2})/(2\\sigma^{2})}$，得$e^{-(q^{,}-\\mu^{2})/(2\\sigma^{2})} =P(q)\\sigma\\sqrt{2\\pi}$\n\n带入E(q)整理得：\n\nE(q) =$s_1q-s_1qF(q)+s_1\\mu F(q)-s_1\\sigma^2p(q)-s_2qF(q)+s_2\\mu F(q)-s_2\\sigma^2p(q)$\n\n\n\n\n\n```python\nfrom scipy import stats\ns = stats.norm.pdf(282,260,50)#p(q)\nf = stats.norm.cdf(282,260,50)#F(q)\nres = 2*282-2*282*f+2*260*f-2*2500*s-1*282*f+1*260*f-1*2500*s\nres\n```\n\n\n    \n\n\n\n\n    465.4576921796353\n\n\n\n**计算结果可知当报童每天进281份报纸可以获得最高利润465元**\n","tags":["python建模"],"categories":["概率"]},{"title":"数据透视表","url":"/2021/09/22/数据透视表/","content":"**数据透视表 pivot table**\n\n\n\n\n\n```python\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndata = pd.read_csv('data1.csv')\ndata.pivot_table(df,index=[u'对手'])#以比赛对手为索引查看数据\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3分命中率</th>\n      <th>助攻</th>\n      <th>命中</th>\n      <th>得分</th>\n      <th>投篮命中率</th>\n      <th>投篮数</th>\n      <th>篮板</th>\n    </tr>\n    <tr>\n      <th>对手</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>76人</th>\n      <td>0.33950</td>\n      <td>10.00</td>\n      <td>9.0</td>\n      <td>28.00</td>\n      <td>0.4405</td>\n      <td>20.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>勇士</th>\n      <td>0.44400</td>\n      <td>11.00</td>\n      <td>10.0</td>\n      <td>27.00</td>\n      <td>0.4350</td>\n      <td>23.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>国王</th>\n      <td>0.28600</td>\n      <td>9.00</td>\n      <td>8.0</td>\n      <td>27.00</td>\n      <td>0.3810</td>\n      <td>21.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>太阳</th>\n      <td>0.54500</td>\n      <td>7.00</td>\n      <td>12.0</td>\n      <td>48.00</td>\n      <td>0.5450</td>\n      <td>22.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>小牛</th>\n      <td>0.46200</td>\n      <td>7.00</td>\n      <td>10.0</td>\n      <td>29.00</td>\n      <td>0.5260</td>\n      <td>19.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>尼克斯</th>\n      <td>0.36900</td>\n      <td>9.50</td>\n      <td>10.5</td>\n      <td>34.00</td>\n      <td>0.4175</td>\n      <td>25.0</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>开拓者</th>\n      <td>0.57100</td>\n      <td>3.00</td>\n      <td>16.0</td>\n      <td>48.00</td>\n      <td>0.5520</td>\n      <td>29.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>掘金</th>\n      <td>0.14300</td>\n      <td>9.00</td>\n      <td>6.0</td>\n      <td>21.00</td>\n      <td>0.3750</td>\n      <td>16.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>步行者</th>\n      <td>0.29150</td>\n      <td>12.50</td>\n      <td>8.5</td>\n      <td>27.50</td>\n      <td>0.3965</td>\n      <td>21.5</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>湖人</th>\n      <td>0.44400</td>\n      <td>9.00</td>\n      <td>13.0</td>\n      <td>36.00</td>\n      <td>0.5910</td>\n      <td>22.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>灰熊</th>\n      <td>0.35025</td>\n      <td>7.75</td>\n      <td>8.5</td>\n      <td>27.25</td>\n      <td>0.4015</td>\n      <td>21.0</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>爵士</th>\n      <td>0.60400</td>\n      <td>8.00</td>\n      <td>13.5</td>\n      <td>42.50</td>\n      <td>0.5905</td>\n      <td>22.0</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>猛龙</th>\n      <td>0.27300</td>\n      <td>11.00</td>\n      <td>8.0</td>\n      <td>38.00</td>\n      <td>0.3200</td>\n      <td>25.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>篮网</th>\n      <td>0.61500</td>\n      <td>8.00</td>\n      <td>13.0</td>\n      <td>37.00</td>\n      <td>0.6500</td>\n      <td>20.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>老鹰</th>\n      <td>0.54500</td>\n      <td>11.00</td>\n      <td>8.0</td>\n      <td>29.00</td>\n      <td>0.5330</td>\n      <td>15.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>骑士</th>\n      <td>0.42900</td>\n      <td>13.00</td>\n      <td>8.0</td>\n      <td>35.00</td>\n      <td>0.3810</td>\n      <td>21.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>鹈鹕</th>\n      <td>0.40000</td>\n      <td>17.00</td>\n      <td>8.0</td>\n      <td>26.00</td>\n      <td>0.5000</td>\n      <td>16.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>黄蜂</th>\n      <td>0.40000</td>\n      <td>11.00</td>\n      <td>8.0</td>\n      <td>27.00</td>\n      <td>0.4440</td>\n      <td>18.0</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\ndata.pivot_table(df,index=[u'主客场',u'对手'])#两个索引\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>3分命中率</th>\n      <th>助攻</th>\n      <th>命中</th>\n      <th>得分</th>\n      <th>投篮命中率</th>\n      <th>投篮数</th>\n      <th>篮板</th>\n    </tr>\n    <tr>\n      <th>主客场</th>\n      <th>对手</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">主</th>\n      <th>76人</th>\n      <td>0.4290</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>29.0</td>\n      <td>0.381</td>\n      <td>21.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>小牛</th>\n      <td>0.4620</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>29.0</td>\n      <td>0.526</td>\n      <td>19.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>尼克斯</th>\n      <td>0.3850</td>\n      <td>10.0</td>\n      <td>12.0</td>\n      <td>37.0</td>\n      <td>0.444</td>\n      <td>27.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>灰熊</th>\n      <td>0.3395</td>\n      <td>8.0</td>\n      <td>9.5</td>\n      <td>30.0</td>\n      <td>0.420</td>\n      <td>22.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>爵士</th>\n      <td>0.8750</td>\n      <td>13.0</td>\n      <td>19.0</td>\n      <td>56.0</td>\n      <td>0.760</td>\n      <td>25.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>猛龙</th>\n      <td>0.2730</td>\n      <td>11.0</td>\n      <td>8.0</td>\n      <td>38.0</td>\n      <td>0.320</td>\n      <td>25.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>鹈鹕</th>\n      <td>0.4000</td>\n      <td>17.0</td>\n      <td>8.0</td>\n      <td>26.0</td>\n      <td>0.500</td>\n      <td>16.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"11\" valign=\"top\">客</th>\n      <th>76人</th>\n      <td>0.2500</td>\n      <td>13.0</td>\n      <td>10.0</td>\n      <td>27.0</td>\n      <td>0.500</td>\n      <td>20.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>勇士</th>\n      <td>0.4440</td>\n      <td>11.0</td>\n      <td>10.0</td>\n      <td>27.0</td>\n      <td>0.435</td>\n      <td>23.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>国王</th>\n      <td>0.2860</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>27.0</td>\n      <td>0.381</td>\n      <td>21.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>太阳</th>\n      <td>0.5450</td>\n      <td>7.0</td>\n      <td>12.0</td>\n      <td>48.0</td>\n      <td>0.545</td>\n      <td>22.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>尼克斯</th>\n      <td>0.3530</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>31.0</td>\n      <td>0.391</td>\n      <td>23.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>开拓者</th>\n      <td>0.5710</td>\n      <td>3.0</td>\n      <td>16.0</td>\n      <td>48.0</td>\n      <td>0.552</td>\n      <td>29.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>步行者</th>\n      <td>0.2500</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>26.0</td>\n      <td>0.429</td>\n      <td>21.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>灰熊</th>\n      <td>0.3610</td>\n      <td>7.5</td>\n      <td>7.5</td>\n      <td>24.5</td>\n      <td>0.383</td>\n      <td>19.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>爵士</th>\n      <td>0.3330</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>29.0</td>\n      <td>0.421</td>\n      <td>19.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>老鹰</th>\n      <td>0.5450</td>\n      <td>11.0</td>\n      <td>8.0</td>\n      <td>29.0</td>\n      <td>0.533</td>\n      <td>15.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>黄蜂</th>\n      <td>0.4000</td>\n      <td>11.0</td>\n      <td>8.0</td>\n      <td>27.0</td>\n      <td>0.444</td>\n      <td>18.0</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n# 设置values的值 筛选所需的列数据 \npd.pivot_table(df,index=[u'主客场',u'胜负'],values=[u'得分',u'助攻',u'篮板',u'投篮数'])\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>助攻</th>\n      <th>得分</th>\n      <th>投篮数</th>\n      <th>篮板</th>\n    </tr>\n    <tr>\n      <th>主客场</th>\n      <th>胜负</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">主</th>\n      <th>胜</th>\n      <td>10.555556</td>\n      <td>34.222222</td>\n      <td>21.222222</td>\n      <td>5.444444</td>\n    </tr>\n    <tr>\n      <th>负</th>\n      <td>8.666667</td>\n      <td>29.666667</td>\n      <td>22.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">客</th>\n      <th>胜</th>\n      <td>9.000000</td>\n      <td>32.000000</td>\n      <td>21.083333</td>\n      <td>4.916667</td>\n    </tr>\n    <tr>\n      <th>负</th>\n      <td>8.000000</td>\n      <td>20.000000</td>\n      <td>19.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n#使用aggfunc 函数计算数据均值\npd.pivot_table(df,index=[u'对手',u'胜负'],values=[u'得分',u'助攻',u'篮板'],aggfunc=[np.mean],fill_value=0)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">mean</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>助攻</th>\n      <th>得分</th>\n      <th>篮板</th>\n    </tr>\n    <tr>\n      <th>对手</th>\n      <th>胜负</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">76人</th>\n      <th>胜</th>\n      <td>13.0</td>\n      <td>27.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>负</th>\n      <td>7.0</td>\n      <td>29.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>勇士</th>\n      <th>胜</th>\n      <td>11.0</td>\n      <td>27.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>国王</th>\n      <th>胜</th>\n      <td>9.0</td>\n      <td>27.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>太阳</th>\n      <th>胜</th>\n      <td>7.0</td>\n      <td>48.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>小牛</th>\n      <th>胜</th>\n      <td>7.0</td>\n      <td>29.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>尼克斯</th>\n      <th>胜</th>\n      <td>9.5</td>\n      <td>34.0</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>开拓者</th>\n      <th>胜</th>\n      <td>3.0</td>\n      <td>48.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>掘金</th>\n      <th>胜</th>\n      <td>9.0</td>\n      <td>21.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>步行者</th>\n      <th>胜</th>\n      <td>12.5</td>\n      <td>27.5</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>湖人</th>\n      <th>胜</th>\n      <td>9.0</td>\n      <td>36.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">灰熊</th>\n      <th>胜</th>\n      <td>7.5</td>\n      <td>33.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>负</th>\n      <td>8.0</td>\n      <td>21.0</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>爵士</th>\n      <th>胜</th>\n      <td>8.0</td>\n      <td>42.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>猛龙</th>\n      <th>负</th>\n      <td>11.0</td>\n      <td>38.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>篮网</th>\n      <th>胜</th>\n      <td>8.0</td>\n      <td>37.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>老鹰</th>\n      <th>胜</th>\n      <td>11.0</td>\n      <td>29.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>骑士</th>\n      <th>胜</th>\n      <td>13.0</td>\n      <td>35.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>鹈鹕</th>\n      <th>胜</th>\n      <td>17.0</td>\n      <td>26.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>黄蜂</th>\n      <th>胜</th>\n      <td>11.0</td>\n      <td>27.0</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n","tags":["python数据透视表"],"categories":["统计"]},{"title":"汽车选购问题","url":"/2021/09/22/汽车选购/","content":"**多属性决策：最优方案的选择，或者按照方案优劣排序，或者给出优劣程度的数量**\n\n多属性决策方案优劣由若干属性（如汽车价格，性能，款式等因素）给以定量或定性表述\n\n属性集合选择原则：\n\n1.全面考虑影响决策目标的因素，选择影响力较强的属性;\n\n2.各属性相关性不要太强\n\n3.尽量选择定量(例如价格等，数值属性)属性，定性(性能，款式等分类)属性要能明确分出优劣程度\n\n4.某个属性对各备选方案差别很小，根据该属性难以辨别方案优劣，这个属性不必入选\n\n5.属性太多时，应该分层，上层每一属性包含下层若干子属性\n\n\n**决策矩阵**\n\n假设3种型号汽车，记做A1,A2,A3。汽车3种属性分别为价格，性能和款式记做X1,X2,X3。\n\n其中性能和款式用打分的方式判断优劣，满分为10分。\n\n|   .    | X1 | X2 | X3 | \n|  -  | -    |-  |-  |\n|  A1    | 25 | 9  | 7  |\n|  A2    | 18 | 7  | 7  |\n|  A3    | 12 | 5  | 5 |\n\n表格对应决策矩阵为$$D=\\left[\\begin{matrix} 25 & 9 & 7 \\\\\n18 & 7  & 7 \\\\\n12 & 5  & 5 \\\\\n\\end{matrix}\\right]$$\n\n矩阵元素$d_{ij}$表示$A_{i}$对$X_{j}$的取值，或称为原始权重\n\n由于决策矩阵属性值物理意义会有不同，所以在分析前要进行标准化处理，标准化处理要区分效益型属性，费用型属性和区间型属性，例如汽车性能，款式为效益型属性，其属性值越大，对决策的重要程度越高。汽车价格则是费用型属性，费用越低，对决策的重要程度越高。\n\n上面决策矩阵明显效益属性占多数，所以先把费用属性（汽车价格）标准化，统一成效益型属性。\n\n汽车价格是逆指标，它的值越小越好，它的作用方向与效益型属性不同，这里就要改变逆指标的性质和作用方向，以达到与效益型属性相同作用方向。这里使用取倒数法\n\n$$D=\\left[\\begin{matrix} \\frac{1}{25} & 9 & 7 \\\\\n\\frac{1}{18} & 7  & 7 \\\\\n\\frac{1}{12} & 5  & 5 \\\\\n\\end{matrix}\\right]$$\n\n\n然后统一进行标准化，前提假设是属性值对决策的重要性是线性关系。因为这里是比较三个方案优劣，所以使用列向量归一化处理，\n\n$r_{ij} = \\frac{d_{ij}}{\\sum_{i=1}^m d_{ij}}$\n\n使列向量分量和为1\n\n\n\n\n\n\n```python\nimport numpy as np\nd = np.array([[1/25,9,7],[1/18,7,7],[1/12,5,5]])\nr = d / d.sum(axis=0)\n#求得归一化后的矩阵\nr\n```\n\n\n\n\n    array([[0.22360248, 0.42857143, 0.36842105],\n           [0.31055901, 0.33333333, 0.36842105],\n           [0.46583851, 0.23809524, 0.26315789]])\n\n\n\n有了归一化后的属性矩阵，下面就要确定各属性的权重，也就是各个属性对决策目标的影响程度。属性权重可以人为根据检验主观判断，也可以偏于客观判断\n\n客观的判断方法有信息熵法：\n\n如果把归一化矩阵各列向量看做信息量的概率分布，那么各型号汽车中某个属性值趋于一致，就是概率差别不大，提供的信息熵就越大，就无法进行优劣的判断。\n\n相反如果信息熵越小，说明提供的信息量越少，不确定性越小，就容易进行优劣的判断\n\n\n结合本案例说明：\n\n比如观察上面归一化后的矩阵第三列，就是汽车款式属性这一列，其差别不大，基本趋于一致，说明这个属性信息熵大，不能通过这个属性比较汽车的忧劣。\n\n这只是通过观察，实际要通过对各属性熵的计算结果进行比较。\n\n各列属性信息熵计算公式：\n$$E_j = -k\\sum_{i=1}^mr_{ij}ln\\;r_{ij} ,k=1\\;/\\;ln \\;,j=1,2,..n $$\n\n$E_j$越大，说明属性相差不大，则这个属性贡献越低,对汽车优劣辨别作用不大，反之是值越小贡献越高。所以这里定义属性X的区分度：\n$F_j=1-E_j,\\;0\\leq F_i \\leq 1$.\n\n\n然后使用归一化的区分度计算各属性权重：\n$w_i = \\frac{F_j}{\\sum_{j=1}^n F_j}\\;,j=1,2,..n$\n\n\n```python\nfrom pandas import DataFrame\n\ndef show_df(data,index=None,column=None):\n    df = DataFrame(data=data,index = index,columns=column)\n    return df\n    \ndef w_value(r):\n    #r = d / d.sum(axis=0)\n    res = []\n    column=['X1-价格','X2-性能','X3-款式']\n    index = ['A1','A2','A3','E-熵','F-区分度','W-权重']\n    for i in range(len(r)):\n        s = sum(r[:,i] * np.log2(r[:,i]))* (-1/np.log2(3))\n        \n        res = np.append(res,s) \n    \n    f  = 1 - res\n\n    #权重 w\n    w = f / sum(f)\n  \n    tmp = np.array([res,f,w])\n    \n    data = np.vstack((r,tmp))\n   \n    df = show_df(data,index,column)\n    return df,w   \n\n\nw_value(r)[0]\n\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X1-价格</th>\n      <th>X2-性能</th>\n      <th>X3-款式</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A1</th>\n      <td>0.223602</td>\n      <td>0.428571</td>\n      <td>0.368421</td>\n    </tr>\n    <tr>\n      <th>A2</th>\n      <td>0.310559</td>\n      <td>0.333333</td>\n      <td>0.368421</td>\n    </tr>\n    <tr>\n      <th>A3</th>\n      <td>0.465839</td>\n      <td>0.238095</td>\n      <td>0.263158</td>\n    </tr>\n    <tr>\n      <th>E-熵</th>\n      <td>0.959351</td>\n      <td>0.974883</td>\n      <td>0.989498</td>\n    </tr>\n    <tr>\n      <th>F-区分度</th>\n      <td>0.040649</td>\n      <td>0.025117</td>\n      <td>0.010502</td>\n    </tr>\n    <tr>\n      <th>W-权重</th>\n      <td>0.532975</td>\n      <td>0.329321</td>\n      <td>0.137703</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n从计算结果来看属性X1的权重最大，其次是X2，X3，前提是决策矩阵的值通过测量或调查是比较客观的情况，通过汽车价格最能辨别汽车优劣。\n\n不过最终要通过计算决策目标（3种汽车）的权重，获得一个选择汽车的最优方案\n\n**第一种方法:加权和法（算术平均）**\n\n计算公式为$$v_i = \\sum_{j=1}^nr_{ij}w_{j}\\;,i=1,2,..m$$ \n\n比如A1汽车对应目标权重为$v_1$,那么计算$v_1$方法就是A1的每个归一化的属性值$r_{1j}$乘以各属性值的权重$w_j$，然后累加.\n\n综合可以得到整个目标权重的线性方程组：\n\n$v_1 = r_{11}w_1+ r_{12}w_2+r_{13}w_3$\n\n$v_2 = r_{21}w_1+ r_{22}w_2+r_{23}w_3  \\Rightarrow$  $\\left[\\begin{matrix} r_{11} & r_{12}&r_{13} \\\\ r_{21} & r_{22}&r_{23} \\\\r_{31} & r_{32}&r_{33} \n\\end{matrix}\\right] \\times \\left[\\begin{matrix} w_1 \\\\w_2\\\\w_3 \\end{matrix}\\right]$\n\n$v_3 = r_{31}w_1+ r_{32}w_2+r_{33}w_3$\n\n\n```python\n#加权和法求解目标权重\ndef w_s(r,w):\n    v = np.dot(r,w)\n  \n    index=['A1','A2','A3']\n    column = ['加权和法']\n    df = show_df(v,index,column)\n    return df\nw = w_value(r)[1]\nw_s(r,w)\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>加权和法</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A1</th>\n      <td>0.311045</td>\n    </tr>\n    <tr>\n      <th>A2</th>\n      <td>0.326027</td>\n    </tr>\n    <tr>\n      <th>A3</th>\n      <td>0.362928</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n**第二种是加权积法（加权几何平均）**\n\n计算公式为：\n\n$$v_i = \\prod_{j=1}^n d_{ij}^{w_j}, \\;w_i = \\frac{F_j}{\\sum_{j=1}^n F_j}\\;,j=1,2,..n$$\n\n则$v_1 = d_{11}^{\\frac{F_1}{\\sum_{j=1}^n F_j}} \\times d_{12}^{\\frac{F_2}{\\sum_{j=1}^n F_j}} \\times d_{13}^{\\frac{F_3}{\\sum_{j=1}^n F_j}} = (d_{11}^{F_1} ) ^\\frac{1}{\\sum_{j=1}^n F_j} \\times (d_{12}^{F_2} ) ^\\frac{1}{\\sum_{j=1}^n F_j} \\times (d_{13}^{F_3} ) ^\\frac{1}{\\sum_{j=1}^n F_j} = \\sqrt[\\sum_{j=1}^n F_j]{d_{11}^{F_1} \\times d_{12}^{F_2} \\times d_{13}^{F_4} } $  \n\n可见目标权重就是对各属性的加权平均值\n\n\n```python\n#加权积法求解目标权重\n\ndef w_m(r,w):\n    d = np.array([[1/25,9,7],[1/18,7,7],[1/12,5,5]])\n    \n    res =[]\n    index=['A1','A2','A3']\n    column = ['加权积法']\n    for i in range(len(w)):\n        s = list(map(lambda x,w:np.power(x,w),d[i],w))\n        vi = np.prod(s)\n        res.append(vi)\n    df = show_df(res,index,column)\n    return df\nw_m(r,w)\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>加权积法</th>\n      <th>加权和法</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A1</th>\n      <td>0.484795</td>\n      <td>0.311045</td>\n    </tr>\n    <tr>\n      <th>A2</th>\n      <td>0.531683</td>\n      <td>0.326027</td>\n    </tr>\n    <tr>\n      <th>A3</th>\n      <td>0.563974</td>\n      <td>0.362928</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n第三种是接近理想解的偏好排序法（topsis法）\n\n理想解法基本思路是，从属性值中构造正理想解与负理想解，然后计算备选方案与理想解的相对接近度，从而判断各备选方案的优劣。\n\n相对接近是指同时考察备选方案与正理想解，负理想解之间的距离,最优方案是离正理想解距离近同时与负理想解距离远的方案。   \n\n理想解步骤：\n\n第一步 因为方案与理想解的距离是用欧氏距离度量，所以先把决策矩阵规范化，让所有属性有相同初始权重\n\n\n```python\nimport pandas as pd\nd = np.array([[1/25,9,7],[1/18,7,7],[1/12,5,5]])\nd_2 = d*d\nr2 = d / np.sqrt(d_2.sum(axis=0))\nindex = ['A1','A2','A3','正理想解','负理想解']\nr2\n```\n\n\n\n\n    array([[0.37089758, 0.7228974 , 0.63116874],\n           [0.51513553, 0.56225353, 0.63116874],\n           [0.77270329, 0.40160966, 0.45083482]])\n\n\n\n第二步 规范化后的矩阵乘以属性权重w,构成矩阵V\n\n\n```python\nw = w_value(r)[1]\nv = np.array([np.dot(r2[:,i],w[i]) for i in range(len(r))]).T\n```\n\n第三步  构建正理想解与负理想解，分别由矩阵v每列最大值与最小值构成\n\n\n```python\n#正理想解 \nv0 = [max(v[:,i]) for i in range(len(v))]\n#负理想解\nv1 = [min(v[:,i]) for i in range(len(v))]\n    \nd = np.vstack((v,v0,v1))\nshow_df(d,index=index)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A1</th>\n      <td>0.197679</td>\n      <td>0.238065</td>\n      <td>0.086914</td>\n    </tr>\n    <tr>\n      <th>A2</th>\n      <td>0.274555</td>\n      <td>0.185162</td>\n      <td>0.086914</td>\n    </tr>\n    <tr>\n      <th>A3</th>\n      <td>0.411832</td>\n      <td>0.132259</td>\n      <td>0.062081</td>\n    </tr>\n    <tr>\n      <th>正理想解</th>\n      <td>0.411832</td>\n      <td>0.238065</td>\n      <td>0.086914</td>\n    </tr>\n    <tr>\n      <th>负理想解</th>\n      <td>0.197679</td>\n      <td>0.132259</td>\n      <td>0.062081</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n第四步  计算方案与正，负理想解的欧式距离\n```\n\n\n```python\nindex = ['与正理想解距离','与负理想解距离']\ncolumn = ['A1','A2','A3']\n\ns0 = [np.sqrt(sum((v[i]-v0)**2)) for i in range(len(v))]\n\ns1 = [np.sqrt(sum((v[i]-v1)**2)) for i in range(len(v))]\nshow_df([s0,s1],index=index,column=column)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>与正理想解距离</th>\n      <td>0.214153</td>\n      <td>0.147118</td>\n      <td>0.108682</td>\n    </tr>\n    <tr>\n      <th>与负理想解距离</th>\n      <td>0.108682</td>\n      <td>0.096567</td>\n      <td>0.214153</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n第五步 计算方案与正理想解相对接近度\n\n$C_i^+ = \\frac{S_i^-}{S_i^+ + S_i^-}\\;,  0<C_i^+<1$\n\n\n```python\nindex=['A1','A2','A3']\ncolumn = ['topsis法']\nc=s1/np.sum([s0,s1],axis=0)\nc =show_df(c,index=index,column=column)\n\npd.concat((w_s(r,w),w_m(r,w),c),axis=1)\n#最后三种方法比较结果可见,方案优劣顺序为A3>A2>A1\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>加权和法</th>\n      <th>加权积法</th>\n      <th>topsis法</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A1</th>\n      <td>0.311045</td>\n      <td>0.484795</td>\n      <td>0.336649</td>\n    </tr>\n    <tr>\n      <th>A2</th>\n      <td>0.326027</td>\n      <td>0.531683</td>\n      <td>0.396278</td>\n    </tr>\n    <tr>\n      <th>A3</th>\n      <td>0.362928</td>\n      <td>0.563974</td>\n      <td>0.663351</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n","tags":["python建模"],"categories":["概率"]},{"title":"孕妇吸烟与胎儿健康","url":"/2021/09/22/线性回归/","content":"\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set(style='white',context='notebook',palette='muted')\ndf = pd.read_csv('data0901.txt',header=None,sep=\"\\t\",skipinitialspace=True)\n#删除多余列\ndf= df.drop(0,axis=1) \ndata=df.copy()\n\n#缺失值（9,99,999为缺失值）用各列的均值替代\ndef missing(columns):\n    m = [9,99,999]\n    mean = columns.mean()\n    columns.replace(m,mean,inplace=True)\nfor col in [1,2,3,4,5,6,7]:\n    missing(data[col])\ndata.round(1)\n    \ndata\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>120.0</td>\n      <td>284.000000</td>\n      <td>0</td>\n      <td>27.0</td>\n      <td>62.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>113.0</td>\n      <td>282.000000</td>\n      <td>0</td>\n      <td>33.0</td>\n      <td>64.0</td>\n      <td>135.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>128.0</td>\n      <td>279.000000</td>\n      <td>0</td>\n      <td>28.0</td>\n      <td>64.0</td>\n      <td>115.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>123.0</td>\n      <td>286.907767</td>\n      <td>0</td>\n      <td>36.0</td>\n      <td>69.0</td>\n      <td>190.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>108.0</td>\n      <td>282.000000</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>67.0</td>\n      <td>125.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1231</th>\n      <td>113.0</td>\n      <td>275.000000</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>60.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1232</th>\n      <td>128.0</td>\n      <td>265.000000</td>\n      <td>0</td>\n      <td>24.0</td>\n      <td>67.0</td>\n      <td>120.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1233</th>\n      <td>130.0</td>\n      <td>291.000000</td>\n      <td>0</td>\n      <td>30.0</td>\n      <td>65.0</td>\n      <td>150.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1234</th>\n      <td>125.0</td>\n      <td>281.000000</td>\n      <td>1</td>\n      <td>21.0</td>\n      <td>65.0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1235</th>\n      <td>117.0</td>\n      <td>297.000000</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>65.0</td>\n      <td>129.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1236 rows × 7 columns</p>\n</div>\n\n\n\n一共1236个出生后至少存活28天的男性新生儿及母亲的数据\n\n要讨论的问题\n\n1.对于新生儿童体重来说，孕妇吸烟是否是比孕妇年龄，身高，体重等更为显著的决定因素\n\n2.孕妇吸烟是否会使早产率增加，怀孕期长短是否对新生儿体重有影响\n\n3.对每个年龄段来说，孕妇吸烟对新生儿体重和早产率的影响是怎样的\n\n\n\n\n```python\n#自定义索引， 依次代表‘婴儿体重’，‘怀孕天数’，‘胎次’，‘孕妇怀孕时年龄’，‘孕妇身高’，‘孕妇体重’，‘是否抽烟’\nn_column={1:'婴儿体重',2:'怀孕天数',3:'胎次',4:'怀孕时年龄',5:'孕妇身高',6:'孕妇体重',7:'是否抽烟'}\ndata.rename(columns=n_column,inplace=True)\ndata\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>婴儿体重</th>\n      <th>怀孕天数</th>\n      <th>胎次</th>\n      <th>怀孕时年龄</th>\n      <th>孕妇身高</th>\n      <th>孕妇体重</th>\n      <th>是否抽烟</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>120.0</td>\n      <td>284.000000</td>\n      <td>0</td>\n      <td>27.0</td>\n      <td>62.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>113.0</td>\n      <td>282.000000</td>\n      <td>0</td>\n      <td>33.0</td>\n      <td>64.0</td>\n      <td>135.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>128.0</td>\n      <td>279.000000</td>\n      <td>0</td>\n      <td>28.0</td>\n      <td>64.0</td>\n      <td>115.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>123.0</td>\n      <td>286.907767</td>\n      <td>0</td>\n      <td>36.0</td>\n      <td>69.0</td>\n      <td>190.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>108.0</td>\n      <td>282.000000</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>67.0</td>\n      <td>125.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1231</th>\n      <td>113.0</td>\n      <td>275.000000</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>60.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1232</th>\n      <td>128.0</td>\n      <td>265.000000</td>\n      <td>0</td>\n      <td>24.0</td>\n      <td>67.0</td>\n      <td>120.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1233</th>\n      <td>130.0</td>\n      <td>291.000000</td>\n      <td>0</td>\n      <td>30.0</td>\n      <td>65.0</td>\n      <td>150.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1234</th>\n      <td>125.0</td>\n      <td>281.000000</td>\n      <td>1</td>\n      <td>21.0</td>\n      <td>65.0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1235</th>\n      <td>117.0</td>\n      <td>297.000000</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>65.0</td>\n      <td>129.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1236 rows × 7 columns</p>\n</div>\n\n\n\n\n```python\n#查看缺失值\ndata.isnull().sum()\n\n```\n\n\n\n\n    婴儿体重     0\n    怀孕天数     0\n    胎次       0\n    怀孕时年龄    0\n    孕妇身高     0\n    孕妇体重     0\n    是否抽烟     0\n    dtype: int64\n\n\n\n\n```python\n#因为是对吸烟与不吸烟孕妇的比较，先分组可视化数据，了解下大概情况\n\nsns.set_style('whitegrid', {'font.sans-serif': ['simhei', 'Arial']})\ncolumns = ['婴儿体重','怀孕天数','怀孕时年龄','孕妇身高','孕妇体重']\n\nplt.figure(figsize=(20,20))\ni=1\nfor col in columns:\n    ax = plt.subplot(3,2,i)#索引从1开始\n    ax = sns.kdeplot(data[data['是否抽烟']==0][col],color='Red',shade=True)\n    ax = sns.kdeplot(data[data['是否抽烟']==1][col],color='Blue',shade=True)\n    ax.set_xlabel(col)\n    ax = ax.legend(['不抽烟','抽烟'])\n    i+=1\nplt.show()\n\n\n\n```\n\n\n![png](output_4_0.png)\n\n\n通过可视化一些数据，可以发现吸烟组与非吸烟组孕妇在年龄，体重，身高，怀孕天数上的分布比较靠近，但是新生婴儿体重的分布有点差距，但也不能明显的说明有差异性，还要进一步通过统计分析来比较\n\n参数估计与假设检验：\n\n\n```python\nfrom scipy import stats\nfrom pandas import DataFrame\ncolumn = ['不吸烟孕妇','吸烟孕妇']\nindex = ['婴儿体重均值点估计','婴儿体重均值区间估计',\n         '婴儿体重低的比例区间估计','怀孕天数均值估计',\n         '怀孕天数均值区间估计','早产率点估计']\n\nno = data['是否抽烟']==0\nyes = data['是否抽烟']==1\n\n#不抽烟---孕妇数量\npw0 = data[no].shape[0]\n#抽烟---孕妇数量\npw1 = data[yes].shape[0]\n\n\ndef dec(list):\n    return [format(i,'.2f') for i in list]\n\n#均值与区间估计\ndef stat(data):\n\n    #体重均值估计\n    mean,std = stats.norm.fit(data)\n    #标准误\n    se = stats.sem(data)\n    #置信区间\n    val = stats.norm.interval(0.96,mean,se)\n   \n    val = dec(val)\n    return mean,val\n    \n\n#婴儿体重低的比例点估计,体重小于2500克=88.2盎司，就是低于标准的\ndef weight_p():\n    \n    #不抽烟---婴儿体重低的数量\n    w0 = data[(no)&(data['婴儿体重']<88.2)].shape[0]\n    #抽烟---婴儿体重低的数量\n    w1 = data[(yes)&(data['婴儿体重']<88.2)].shape[0]\n\n    #不抽烟---婴儿体重低比例\n    b_w0 = w0/pw0\n    #抽烟---婴儿体重低比例\n    b_w1 = w1/pw1\n    return [b_w0,b_w1]\n\n#早产率点估计\ndef premature_p():\n    #不吸烟孕妇早产比例 即孕期小于259天的比例\n    p0 = data[(no)&(data['怀孕天数']<259)].shape[0]\n    p1  =data[(yes)&(data['怀孕天数']<259)].shape[0]\n    \n    #不抽烟早产比\n    pp0=p0/pw0\n    \n    #抽烟早产比\n    pp1=p1/pw1\n    return [pp0,pp1]\n\n#新生婴儿体重均值与区间估计\ndef baby_w():\n    w0 = data[no]['婴儿体重']\n    w1 = data[yes]['婴儿体重']\n\n    #不吸烟体重均值与区间估计\n    r0 = stat(w0)\n    #吸烟体重均值与区间估计\n    r1  = stat(w1)\n    return [r0[0],r1[0]],[r0[1],r1[1]]\n\n#孕期均值与区间估计\ndef pre_day():\n    p0 = data[no]['怀孕天数']\n    p1 = data[yes]['怀孕天数']\n    \n    r0 = stat(p0)\n    r1 = stat(p1)\n    return [r0[0],r1[0]],[r0[1],r1[1]]\n\n\n    \n    \n\n#体重点估计\nw_m = baby_w()[0]\n#体重均值区间\nw_in = baby_w()[1]\n#体重低比例点估计\nw_p=weight_p()\n#孕期均值\np_m = pre_day()[0]\n#孕期区间\np_in= pre_day()[1]\n#早产率点估计\np_p = premature_p()\n\nest_data = [w_m,w_in,w_p,p_m,p_in,p_p]\n\ntable = DataFrame(data=est_data,index=index,columns=column)\n\ntable \n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>不吸烟孕妇</th>\n      <th>吸烟孕妇</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>婴儿体重均值点估计</th>\n      <td>123.241</td>\n      <td>114.492</td>\n    </tr>\n    <tr>\n      <th>婴儿体重均值区间估计</th>\n      <td>[121.94, 124.54]</td>\n      <td>[112.81, 116.17]</td>\n    </tr>\n    <tr>\n      <th>婴儿体重低的比例区间估计</th>\n      <td>0.0309973</td>\n      <td>0.0826446</td>\n    </tr>\n    <tr>\n      <th>怀孕天数均值估计</th>\n      <td>280.268</td>\n      <td>278.053</td>\n    </tr>\n    <tr>\n      <th>怀孕天数均值区间估计</th>\n      <td>[279.02, 281.52]</td>\n      <td>[276.65, 279.46]</td>\n    </tr>\n    <tr>\n      <th>早产率点估计</th>\n      <td>0.0754717</td>\n      <td>0.0847107</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n参数估计的结果与可视化的结果都显示孕妇吸烟对婴儿体重有一定影响，吸烟孕妇的新生儿体重平均低9oz\n其他的参数差别不显著。\n\n这种由吸烟引起的各项指标差异，还要进行假设检验进一步确认\n\n\n```python\n#孕妇抽烟与不抽烟婴儿体重低比例的假设检验\n#这里零假设是不抽烟孕妇的婴儿体重低比例（p0)大于不抽烟(p1)的\n#H0:p0》p1,H1:p0<p1\n\n#默认显著水平0.05 Z统计量检验\n#比例不为零的假设\ndef w_low_test():\n    \n    #不抽烟---婴儿体重低的数量\n    w0 = data[(no)&(data['婴儿体重']<88.2)].shape[0]\n    #抽烟---婴儿体重低的数量\n    w1 = data[(yes)&(data['婴儿体重']<88.2)].shape[0]\n    n0 = data[no]['婴儿体重'].shape[0]\n    n1 = data[yes]['婴儿体重'].shape[0]\n\n    p0 = w0/n0\n    p1 = w1/n1  \n    m=(p0*(1-p0))/n0 + (p1*(1-p1))/n1\n    z = (p0-p1)-0.05 / np.sqrt(m)\n\n    z_a = stats.norm.isf(0.05)#正态分位点 ，求分布函数的逆，单侧检验\n    if abs(z)>z_a:\n        return '拒绝H0,接受H1'\n    else:\n        return '不能拒绝H0'\n\n    \ndef ttest(a,b):\n    n = len(a)+len(b)\n    t = stats.ttest_ind(a,b,alternative='greater')\n    p_value=t[1]\n    t_value=t[0]\n    t_score = stats.t.isf(0.05,df=n)#单侧分位点\n    if t_value>t_score:\n        return '拒绝H0,接受H1'\n    else:\n        return '不能拒绝H0'\n\n\n#早产率假设检验\n#从点估计来看吸烟与不吸烟早产率差别不明显，\n#H0:μ0=μ1；H1：μ0！=μ1 想要证明他们有差异，建立两总体比例相等的假设\ndef pre_p():\n    #不抽烟---\n    w0 = data[(no)&(data['怀孕天数']<259)].shape[0]\n    #抽烟---\n    w1 = data[(yes)&(data['怀孕天数']<259)].shape[0]\n    n0 = data[no]['怀孕天数'].shape[0]\n    n1 = data[yes]['怀孕天数'].shape[0]\n\n    p0 = w0/n0\n    p1 = w1/n1  \n    p = (w0+w1)/(n0+n1)\n    m= p*(1-p)*(1/n0+1/n1)\n    z = (p0-p1) / np.sqrt(m)\n\n\n    z_a = stats.norm.isf(0.05/2)#双侧检验\n\n    if abs(z)>z_a:\n        return '拒绝H0,接受H1'\n    else:\n        return '不能拒绝H0'\n    \n\n\n    \n#婴儿体重均值检验\n#H0:μ0<=μ1；H1：μ0>μ1  单侧检验\n#假设不吸烟孕妇新生儿体重均值小于吸烟的 \nw_a = data[no]['婴儿体重']\nw_b = data[yes]['婴儿体重']\nr0 = ttest(w_a,w_b) \n\n\n#孕期均值假设检验\n#H0:μ0<=μ1；H1：μ0>μ1  右单侧检验\n#假设不吸烟的孕期小于吸烟的\npre_a = data[no]['怀孕天数']\npre_b = data[yes]['怀孕天数']\nr1 = ttest(pre_a,pre_b)\n\n#新生儿体重低的比例假设检验 \nr2 = w_low_test()\n#早产率假设检验\nr3 =  pre_p()\ntest_data = [r0,r1,r2,r3]\n```\n\n\n```python\nindex =['新生儿体重均值假设检验   H0:μ0<=μ1;H1:μ0>μ1  ','新生儿体重低的比例假设检验   H0:p0>=p1,H1:p0<p1',\n        '怀孕期均值假设检验   H0:μ0<=μ1;H1:μ0>μ1  ','早产率假设检验   H0:μ0=μ1;H1:μ0!=μ1']\ncolumn = ['检验结果']\n\ntable=DataFrame(data = test_data,index=index,columns=column)\ntable\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>检验结果</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>新生儿体重均值假设检验   H0:μ0&lt;=μ1;H1:μ0&gt;μ1</th>\n      <td>拒绝H0,接受H1</td>\n    </tr>\n    <tr>\n      <th>新生儿体重低的比例假设检验   H0:p0&gt;=p1,H1:p0&lt;p1</th>\n      <td>拒绝H0,接受H1</td>\n    </tr>\n    <tr>\n      <th>怀孕期均值假设检验   H0:μ0&lt;=μ1;H1:μ0&gt;μ1</th>\n      <td>拒绝H0,接受H1</td>\n    </tr>\n    <tr>\n      <th>早产率假设检验   H0:μ0=μ1;H1:μ0!=μ1</th>\n      <td>不能拒绝H0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n关于假设检验结果解释\n首先前三个是有方向的检验，通过一个比较苛刻的显著性水平（0.05）来反驳H0，从而证明H1的成立,这里把想证明不正确的命题作为原假设  \n\n从结果看出吸烟孕妇比不吸烟孕妇的新生儿体重低,并且新生儿体重低的比例要高。而早产率的差异并不显著。早产与否对应着孕期的长短，所以\n为了解决提出的第二个问题，即孕妇吸烟是否会使早产率增加，怀孕期长度是否对新生儿体重有影响。我们还需要进一步借助其他方法充分利用数据进行分析。\n\n\n经过前面的参数估计和假设检验，可以看出吸烟对婴儿体重有着显著的影响，但是这有可能是多因素影响的结果，比如怀孕期，孕妇体重，早产率等。\n所以这里要利用回归分析，建立婴儿体重与孕妇吸烟状况,怀孕期等因素的回归模型来具体分析影响新生儿体重的因素。\n\n首先用一元线性回归分析吸烟孕妇新生儿体重与孕期的关系\n\n\n假设用y和x分别表示新生儿体重和怀孕期两个变量，二者关系可以用一次函数$y = b_0+b_1x$来描述\n首先计算系数$b_0和b_1$\n\n$b_1=\\frac{n\\sum_{i=1}^nx_iy_i -\\sum_{i=1}^nx_i\\sum_{i=1}^ny_i}{n\\sum_{i=1}^nx_i^2-(\\sum_{i=1}^nx_i)^2}$\n\n$b_0 = \\overline{y} - b_1\\overline{x}$,其中$\\overline{y} = \\frac{\\sum_{i=1}^ny_i}{n},\\overline{x}=\\frac{\\sum_{i=1}^nx_i}{n}$\n\n\n```python\nimport matplotlib.pyplot as plt\nimport scipy.stats as st\ny = data[yes]['婴儿体重']\nx = data[yes]['怀孕天数']\n\nclass LR:\n    def init():\n        self.b0=None\n        self.b1=None\n        self._y =None\n        self.x = None\n        self.y = None\n        self.n = None\n        self.sse = None\n        self.ssr= None\n        self.sst = None\n        self.s=None\n        \n    def fit(self,x,y):\n        self.n = len(x)\n        self.b1 = ((self.n*np.dot(x,y)) - sum(x)*sum(y)) / (self.n*np.dot(x,x) - pow(sum(x),2))\n        self.b0 = (sum(y) / self.n)- self.b1*(sum(x)/ self.n)\n        self._y = self.b0+np.dot(self.b1,x)\n        self.x= x\n        self.y =y\n        #回归平方和  x与y之间线性关系引起y的变换部分\n        self.ssr = sum(pow(self._y-sum(self.y)/self.n,2))\n        #残差平方和  其他因素对y的影响\n        self.sse = sum(pow(self.y-self._y,2))\n        #总平方和\n        self.sst = self.ssr+self.sse\n        #估计标准误差  反映了用估计的回归方程预测因变量y时预测误差大小\n        #值越小模型精度越高 \n        self.s = np.sqrt(self.sse/(self.n-2))\n        \n        return self\n\n    \n    def coef(self):\n         #t临界值  双侧\n        t_p = st.t.isf(0.05/2,df=self.n-2)\n        x_mean = np.mean(self.x)\n        tmp =sum(np.power(self.x-np.mean(self.x),2))\n       \n        #系数置信区间\n        #截距b0区间\n        b0_upper = self.b0+t_p * self.s * np.sqrt(1/self.n+x_mean/tmp)\n        b0_lower = self.b0-t_p * self.s * np.sqrt(1/self.n+x_mean/tmp)\n        \n        #斜率b1区间\n        b1_upper = self.b1+t_p*self.s/np.sqrt(tmp)\n        b1_lower = self.b1-t_p*self.s/np.sqrt(tmp)\n       \n        column = ['回归系数','系数估计值','系数置信区间']\n        res= [['b0',self.b0,[b0_lower,b0_upper]],['b1',self.b1,[b1_lower,b1_upper]]]\n        df = self._df(res,column=column)\n        return df\n        \n\n    \n    #判定值\n    def deter(self):\n      \n        r_2 = self.ssr /self.sst\n        #线性关系的检验  检验x与y之间的线性关系是否显著\n        #f-value  (ssr/1) / (sse/(n-2))\n        #根据分子分母自由度 获取f分布临界值\n        f_value =  (self.ssr/1) / (self.sse/(self.n-2))\n        f_point = st.f.isf(0.05,1,self.n-2)\n        \n        column =['判定系数R^2','估计标准误差 S','F检验',\n        'F临界值']\n        res = [[r_2,self.s,f_value,f_point]]\n        \n        df = self._df(res,column=column)\n        return df\n    #标准化残差\n    def residual(self):\n        e = (self.y-self._y) / self.s\n        e.name='标准残差'\n\n        sns.residplot(x=self.x,y=e,scatter_kws={\"s\":50})\n        return e\n\n    def _df(self,data,index=None,column=None):\n        df  =DataFrame(data=data,index=index,columns=column)\n        return df\n        \n        \n    \n    def draw(self,title=None):\n        x = self.x\n        y = self.b0+self.b1*x\n        fig,ax = plt.subplots(figsize=(8,5))\n        ax.scatter(self.x,self.y,s=100,alpha=0.5)\n        ax.set_xlabel('days')\n        ax.set_ylabel('weight')\n        plt.plot(x,y,'g',linewidth=2)\n        plt.title(title,fontsize=12)\n        plt.show()\n        \n        \n    \n        \nlr = LR()\nl = lr.fit(x,y)\nl.draw()\nl.coef()\n\n\n\n```\n\n\n![png](output_11_0.png)\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>回归系数</th>\n      <th>系数估计值</th>\n      <th>系数置信区间</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b0</td>\n      <td>-48.911986</td>\n      <td>[-51.00605796546445, -46.817913853337345]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b1</td>\n      <td>0.587673</td>\n      <td>[0.4943557914718013, 0.6809895062587543]</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\nl.deter()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>判定系数R^2</th>\n      <th>估计标准误差 S</th>\n      <th>F检验</th>\n      <th>F临界值</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.241088</td>\n      <td>15.690473</td>\n      <td>153.119575</td>\n      <td>3.860824</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n一元线性回归结果解释：\n\n这是对吸烟孕妇孕期及新生儿体重建立的回归模型，其目的是通过模型判断吸烟状况与婴儿体重大小的关系。\n\n回归系数b0代表估计方程的截距,b1代表斜率.b1的值说明吸烟孕妇的怀孕期每增加一天，新生儿体重平均增加0.6盎司。\n\n判定系数为0.24，说明y的24%由x决定，估计标准误差为15.69，跟估计误差相关的系数置信区间也比较大，由判定系数与估计标准误差可以判定回归线的拟合优度不好。\n\nf检验的结果为153.11,显著水平为0.05时的F临界值为3.86，按照假设H0：b1=0,应该拒绝H0，说明自变量与因变量有显著关系\n\n这些所做的估计和预测都是建立在误差项的假设前提下的。如果误差项假设不成立，所做的结果也是不靠谱的。\n\n**残差分析**\n\n\n```python\ne = l.residual()\n```\n\n\n![png](output_14_0.png)\n\n\n观察残差图可以发现有部分残差落在95%置信区间外，残差值总体来说是位于一条水平带中间的。这说明上面所做的估计和预测以及对误差项的假设都是成立的。\n\n同时可以考虑将偏离置信区间的异常值去掉，然后在进行建模，看是否能提高模型精度\n\n\n```python\n#异常值\ndef find_outlier(data):\n    data_std=np.std(data)\n    data_mean = np.mean(data)\n    #残差95%置信区间\n    outlier_cut = 2*data_std\n    low = data_mean - outlier_cut\n    upper = data_mean + outlier_cut\n    #异常值标记为0\n    data = data.apply(lambda x: x if low<x<upper else 0)\n    return data\n    \nd = find_outlier(e)\n\nnew_x = x[d[d!=0].index]\nnew_y = y[d[d!=0].index]\nnew_lr = LR()\nnl = new_lr.fit(new_x,new_y)\nnl.coef()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>回归系数</th>\n      <th>系数估计值</th>\n      <th>系数置信区间</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b0</td>\n      <td>-48.338869</td>\n      <td>[-50.22865010832668, -46.44908866476863]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b1</td>\n      <td>0.583635</td>\n      <td>[0.4989756243007572, 0.6682937813575701]</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\nnl.deter()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>判定系数R^2</th>\n      <th>估计标准误差 S</th>\n      <th>F检验</th>\n      <th>F临界值</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.286541</td>\n      <td>13.700063</td>\n      <td>183.541689</td>\n      <td>3.861887</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\ne1 = nl.residual()\n\n```\n\n\n![png](output_18_0.png)\n\n\n除掉异常值后用新的数据建模发现判定系数变大了，说明X对y的影响变大了。\n\n同时F检验值变大，估计标准误差变小，也就是模型的精度提高了\n\n从残差图来看，整个残差带更集中，异常残差值变少了\n\n然后对不吸烟孕妇的数据进行同样的建模，用来与吸烟孕妇建模结果对比。\n\n\n```python\ny1 = data[no]['婴儿体重']\nx1 = data[no]['怀孕天数']\n\nlr2 = LR()\n#去除异常值\nl2 =lr2.fit(x1,y1)\ne1 = l2.residual()\nd1 = find_outlier(e1)\nnew_x1 = x1[d1[d1!=0].index]\nnew_y1 = y1[d1[d1!=0].index]\n\n#剔除异常值后新模型\nlr3 = LR()\nl3 =lr3.fit(new_x1,new_y1)\nl3.draw('不吸烟孕妇')\n\nl.draw('吸烟孕妇')\nl3.coef()\n```\n\n\n![png](output_20_0.png)\n\n\n\n![png](output_20_1.png)\n\n\n\n![png](output_20_2.png)\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>回归系数</th>\n      <th>系数估计值</th>\n      <th>系数置信区间</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b0</td>\n      <td>39.056124</td>\n      <td>[37.5704592021892, 40.54178896371772]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b1</td>\n      <td>0.301041</td>\n      <td>[0.23535920710136213, 0.366722620008604]</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n由拟合图看出，不吸烟孕妇孕期更加集中。孕期每增长一天，新生儿体重增加0.3oz,要比吸烟孕妇新生儿体重增加少\n\n\n```python\ne3 = l3.residual()\nl3.deter()\n\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>判定系数R^2</th>\n      <th>估计标准误差 S</th>\n      <th>F检验</th>\n      <th>F临界值</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.10382</td>\n      <td>13.465118</td>\n      <td>80.977367</td>\n      <td>3.854797</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n![png](output_22_1.png)\n\n\n从判定系数来看，好像不吸烟孕妇的婴儿体重受孕期的影响较小\n\n\n```python\n\n```\n","tags":["python建模"],"categories":["概率"]}]